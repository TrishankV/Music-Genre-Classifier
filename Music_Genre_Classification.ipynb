{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMi1/H9N48fVT/m92s97eMt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TrishankV/Music-Genre-Classifier/blob/main/Music_Genre_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $PROJECT_ROOT\n",
        "!mkdir -p data/GTZAN\n",
        "!cd data/GTZAN"
      ],
      "metadata": {
        "id": "cEv-mnL7ItoI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!if [ ! -f ~/.kaggle/kaggle.json ]; then\n",
        "!    echo \"Error: ~/.kaggle/kaggle.json does not exist!\"\n",
        "!    echo \"Please create your kaggle.json file from https://www.kaggle.com/<username>/account and place it under ~/.kaggle/kaggle.json, then run this script.\"\n",
        "!    exit 1\n",
        "!fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdI__sZFJvzj",
        "outputId": "809273e9-f6cd-48db-b50f-4fafb0f065cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 2: syntax error: unexpected end of file\n",
            "Error: ~/.kaggle/kaggle.json does not exist!\n",
            "Please create your kaggle.json file from https://www.kaggle.com/<username>/account and place it under ~/.kaggle/kaggle.json, then run this script.\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `fi'\n",
            "/bin/bash: -c: line 1: `fi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification\n",
        "!unzip gtzan-dataset-music-genre-classification.zip"
      ],
      "metadata": {
        "id": "oKlrAS9MJ7a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s Data/genres_original ./genres\n"
      ],
      "metadata": {
        "id": "Gnqq4hzFKBF3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/coreyker/dnn-mgr/bdad579ea6cb37b665ea6019fe1026a6ce20cbc7/gtzan/train_filtered.txt\n",
        "# jazz.00054.wav is corrupted in kaggle source, remove it from train_filtered.txt\n",
        "!sed -e '/jazz.00054.wav/d' train_filtered.txt > _train_filtered.txt\n",
        "!mv _train_filtered.txt train_filtered.txt\n",
        "!wget https://raw.githubusercontent.com/coreyker/dnn-mgr/bdad579ea6cb37b665ea6019fe1026a6ce20cbc7/gtzan/valid_filtered.txt\n",
        "!wget https://raw.githubusercontent.com/coreyker/dnn-mgr/bdad579ea6cb37b665ea6019fe1026a6ce20cbc7/gtzan/test_filtered.txt\n",
        "\n",
        "# beat tracking label\n",
        "!wget http://anasynth.ircam.fr/home/system/files/attachment_uploads/marchand/private/GTZAN-Rhythm_v2_ismir2015_lbd_2015-10-28.tar_.gz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmIG-FUIKmLW",
        "outputId": "2e233f35-3a89-4fd3-c3d7-80bea38e484c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-28 17:00:34--  https://raw.githubusercontent.com/coreyker/dnn-mgr/bdad579ea6cb37b665ea6019fe1026a6ce20cbc7/gtzan/train_filtered.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10152 (9.9K) [text/plain]\n",
            "Saving to: ‘train_filtered.txt’\n",
            "\n",
            "\rtrain_filtered.txt    0%[                    ]       0  --.-KB/s               \rtrain_filtered.txt  100%[===================>]   9.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-07-28 17:00:34 (94.0 MB/s) - ‘train_filtered.txt’ saved [10152/10152]\n",
            "\n",
            "--2024-07-28 17:00:34--  https://raw.githubusercontent.com/coreyker/dnn-mgr/bdad579ea6cb37b665ea6019fe1026a6ce20cbc7/gtzan/valid_filtered.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4522 (4.4K) [text/plain]\n",
            "Saving to: ‘valid_filtered.txt’\n",
            "\n",
            "valid_filtered.txt  100%[===================>]   4.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-07-28 17:00:34 (47.5 MB/s) - ‘valid_filtered.txt’ saved [4522/4522]\n",
            "\n",
            "--2024-07-28 17:00:35--  https://raw.githubusercontent.com/coreyker/dnn-mgr/bdad579ea6cb37b665ea6019fe1026a6ce20cbc7/gtzan/test_filtered.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6616 (6.5K) [text/plain]\n",
            "Saving to: ‘test_filtered.txt’\n",
            "\n",
            "test_filtered.txt   100%[===================>]   6.46K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-07-28 17:00:35 (44.5 MB/s) - ‘test_filtered.txt’ saved [6616/6616]\n",
            "\n",
            "--2024-07-28 17:00:35--  http://anasynth.ircam.fr/home/system/files/attachment_uploads/marchand/private/GTZAN-Rhythm_v2_ismir2015_lbd_2015-10-28.tar_.gz\n",
            "Resolving anasynth.ircam.fr (anasynth.ircam.fr)... 129.102.1.120, 2001:660:3004:4000::120:80\n",
            "Connecting to anasynth.ircam.fr (anasynth.ircam.fr)|129.102.1.120|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1179400 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘GTZAN-Rhythm_v2_ismir2015_lbd_2015-10-28.tar_.gz’\n",
            "\n",
            "GTZAN-Rhythm_v2_ism 100%[===================>]   1.12M  1.03MB/s    in 1.1s    \n",
            "\n",
            "2024-07-28 17:00:36 (1.03 MB/s) - ‘GTZAN-Rhythm_v2_ismir2015_lbd_2015-10-28.tar_.gz’ saved [1179400/1179400]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xzvf GTZAN-Rhythm_v2_ismir2015_lbd_2015-10-28.tar_.gz\n",
        "\n",
        "!cd $PROJECT_ROOT"
      ],
      "metadata": {
        "id": "0CGFHMt_KtnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: list all the files and every file in DATA\n",
        "!ls -l /content/Data\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFMwHMZvKzjd",
        "outputId": "e6c9a820-a532-4b5c-d2c3-95f66c65fd5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 11908\n",
            "-rw-r--r--  1 root root  1108271 Mar 24  2020 features_30_sec.csv\n",
            "-rw-r--r--  1 root root 11075018 Mar 24  2020 features_3_sec.csv\n",
            "drwxr-xr-x 12 root root     4096 Jul 28 13:46 genres_original\n",
            "drwxr-xr-x 12 root root     4096 Jul 28 13:46 images_original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import soundfile as sf\n",
        "import audioread\n"
      ],
      "metadata": {
        "id": "7lx3Cs4NLTzJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(file_name):\n",
        "  try :\n",
        "\n",
        "    audio , sample_rate = librosa.load(file_name , res_type = \"kaiser_fast\")\n",
        "    mel = librosa.feature.melspectrogram(y = audio , sr = sample_rate)\n",
        "    mel_db = librosa.power_to_db(mel)\n",
        "    return mel_db\n",
        "  except (sf.LibsndfileError , audioread.NoBackendError) as e :\n",
        "    print(f\"Error: {file_name , e}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "QHDoI1U0LwlF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/Data/genres_original'"
      ],
      "metadata": {
        "id": "hK0SJxyZMdTM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_name = os.listdir(path)\n",
        "gen_name.sort()"
      ],
      "metadata": {
        "id": "6RPIGy8YMvWb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPc09_0WN3pX",
        "outputId": "eef278c2-b84e-4d1d-d241-9c288bbe0ac2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['blues',\n",
              " 'classical',\n",
              " 'country',\n",
              " 'disco',\n",
              " 'hiphop',\n",
              " 'jazz',\n",
              " 'metal',\n",
              " 'pop',\n",
              " 'reggae',\n",
              " 'rock']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Dict = [os.path.join(path , i ) for i in gen_name]\n",
        "print(Dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8IeJdHSM1X2",
        "outputId": "def3487b-47ef-4d06-8580-f3c693d5e9dc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/Data/genres_original/blues', '/content/Data/genres_original/classical', '/content/Data/genres_original/country', '/content/Data/genres_original/disco', '/content/Data/genres_original/hiphop', '/content/Data/genres_original/jazz', '/content/Data/genres_original/metal', '/content/Data/genres_original/pop', '/content/Data/genres_original/reggae', '/content/Data/genres_original/rock']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Dictionary =  {name: index for index, name in enumerate(gen_name)}\n"
      ],
      "metadata": {
        "id": "E3F1KlTuNP3H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biogfav3icwt",
        "outputId": "8439d541-7724-444d-efaa-57e87da20b31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'blues': 0,\n",
              " 'classical': 1,\n",
              " 'country': 2,\n",
              " 'disco': 3,\n",
              " 'hiphop': 4,\n",
              " 'jazz': 5,\n",
              " 'metal': 6,\n",
              " 'pop': 7,\n",
              " 'reggae': 8,\n",
              " 'rock': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data , labels = [] , []"
      ],
      "metadata": {
        "id": "nxOGhELtNm_O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in Dict:\n",
        "  for j in os.listdir(i):\n",
        "    if j.endswith('.wav'):\n",
        "      mel_spectogram /= extract_features(os.path.join(i , j))\n",
        "      if mel_spectogram is not None:\n",
        "        data.append(mel_spectogram)\n",
        "        labels.append(Dictionary[i.split('/')[-1]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSCui9A1N-jD",
        "outputId": "6f03e561-ab58-401d-fa85-83c87da16d66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-a65556fedc4b>:4: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio , sample_rate = librosa.load(file_name , res_type = \"kaiser_fast\")\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: ('/content/Data/genres_original/jazz/jazz.00054.wav', NoBackendError())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ha1Y3GGjEQW",
        "outputId": "8e96a393-7622-46ef-bd67-aeccd4becb9d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "999"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvPcZOe8jujF",
        "outputId": "6389f84c-3429-49b6-a3cd-9c53fbaf5eb6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "999"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "nCBleVjtmPbw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_data(data):\n",
        "  return cv2.resize(data , (128 , 128))\n"
      ],
      "metadata": {
        "id": "fVWe4MA5lXWs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_data = [resize_data(i) for i in data if i is not None]\n",
        "r_data = np.array(r_data)"
      ],
      "metadata": {
        "id": "rz8I4bU1mTwS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg_xbXM9meol",
        "outputId": "45e6b833-c031-4c9f-d961-621ac20661ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(999, 128, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = labels[:len(r_data)]\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "5PdodkTGmzT8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6mOy3Wum13k",
        "outputId": "907b538a-c4f7-4e68-f679-46a2e897a25d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(999,)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_data = r_data.reshape(r_data.shape[0] , 128 , 128 , 1)"
      ],
      "metadata": {
        "id": "6Kw4y7Fom3GU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_data = r_data / 255.0"
      ],
      "metadata": {
        "id": "RcZPuEpBnhU6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder as le\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "ovngRMkdnjZH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = le()\n",
        "labels = le.fit_transform(labels)\n",
        "labels = to_categorical(labels)"
      ],
      "metadata": {
        "id": "gs2im94ony2P"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRzkx1HmoAU4",
        "outputId": "10b54936-9fd5-4a6a-8897-fa20a3c1dcf7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(999, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "pOmGXH3hoDR_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train , X_test , y_train , y_test = train_test_split(r_data , labels , test_size = 0.2 , random_state = 42)"
      ],
      "metadata": {
        "id": "O6aIPbfkohjF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-600oFLoj_s",
        "outputId": "b91e3a30-b352-420a-9c2a-4ff9ff5ae3fd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(799, 128, 128, 1)\n",
            "(200, 128, 128, 1)\n",
            "(799, 10)\n",
            "(200, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer , Conv2D , MaxPooling2D , Flatten , Dense , Dropout , BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "zCIvgAbyondN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_s = 0.0001"
      ],
      "metadata": {
        "id": "g2BIleZbfCUX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape = (128 , 128 , 1)))\n",
        "model.add(InputLayer(input_shape=(128, 128, 1)))\n",
        "model.add(Conv2D(32, (5, 5), activation='relu' , kernel_regularizer=l2(r_s)))\n",
        "model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "model.add(Conv2D(64, (5, 5), activation='relu' , kernel_regularizer=l2(r_s)))\n",
        "model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "model.add(Conv2D(128, (5, 5), activation='relu' , kernel_regularizer=l2(r_s)))\n",
        "model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu',kernel_regularizer=l2(r_s)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu',kernel_regularizer=l2(r_s)))\n",
        "model.add(Dense(10, activation='softmax',kernel_regularizer=l2(r_s)))  # Output layer with softmax for classification\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "v1e8MS1Do11Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6A7Xixdo3oF",
        "outputId": "24c4fd01-cdd8-42da-ede1-ad748c37e1aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        multiple                  0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 124, 124, 32)      832       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 62, 62, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 58, 58, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 29, 29, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 25, 25, 128)       204928    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 13, 13, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 21632)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               2769024   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3034954 (11.58 MB)\n",
            "Trainable params: 3034954 (11.58 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train , y_train , epochs = 50 , batch_size = 32 , validation_data = (X_test , y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOfQNJfJpK8s",
        "outputId": "e52587d1-44e7-4c8d-d826-b856d8b0719e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 49s 2s/step - loss: 2.2681 - accuracy: 0.1790 - val_loss: 2.2488 - val_accuracy: 0.1600\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 2.1038 - accuracy: 0.1902 - val_loss: 2.0286 - val_accuracy: 0.2000\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 2.0311 - accuracy: 0.2516 - val_loss: 2.0110 - val_accuracy: 0.2700\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 1.9478 - accuracy: 0.2979 - val_loss: 1.9283 - val_accuracy: 0.2750\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 47s 2s/step - loss: 1.8826 - accuracy: 0.3317 - val_loss: 1.7629 - val_accuracy: 0.3750\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 1.8445 - accuracy: 0.3479 - val_loss: 1.7558 - val_accuracy: 0.3400\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 1.6853 - accuracy: 0.3842 - val_loss: 1.6201 - val_accuracy: 0.4050\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 1.6489 - accuracy: 0.3905 - val_loss: 1.6365 - val_accuracy: 0.4450\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 48s 2s/step - loss: 1.5953 - accuracy: 0.4068 - val_loss: 1.5166 - val_accuracy: 0.4850\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 1.5231 - accuracy: 0.4568 - val_loss: 1.4456 - val_accuracy: 0.4650\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 46s 2s/step - loss: 1.4264 - accuracy: 0.4743 - val_loss: 1.4883 - val_accuracy: 0.4150\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 1.4223 - accuracy: 0.4731 - val_loss: 1.4716 - val_accuracy: 0.4850\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 47s 2s/step - loss: 1.3834 - accuracy: 0.4956 - val_loss: 1.4619 - val_accuracy: 0.4450\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 1.3592 - accuracy: 0.4919 - val_loss: 1.4068 - val_accuracy: 0.4700\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 46s 2s/step - loss: 1.2883 - accuracy: 0.5307 - val_loss: 1.3042 - val_accuracy: 0.5300\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 46s 2s/step - loss: 1.2702 - accuracy: 0.5407 - val_loss: 1.2954 - val_accuracy: 0.5550\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 48s 2s/step - loss: 1.2424 - accuracy: 0.5544 - val_loss: 1.2295 - val_accuracy: 0.5900\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 1.1769 - accuracy: 0.5820 - val_loss: 1.2252 - val_accuracy: 0.5950\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 1.1459 - accuracy: 0.5957 - val_loss: 1.2331 - val_accuracy: 0.6100\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 44s 2s/step - loss: 1.0796 - accuracy: 0.6270 - val_loss: 1.1331 - val_accuracy: 0.6450\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 48s 2s/step - loss: 1.0275 - accuracy: 0.6283 - val_loss: 1.2148 - val_accuracy: 0.6050\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.9777 - accuracy: 0.6433 - val_loss: 1.1796 - val_accuracy: 0.6150\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.9965 - accuracy: 0.6608 - val_loss: 1.2286 - val_accuracy: 0.6200\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 1.0122 - accuracy: 0.6395 - val_loss: 1.2137 - val_accuracy: 0.6000\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 48s 2s/step - loss: 0.9182 - accuracy: 0.6846 - val_loss: 1.1335 - val_accuracy: 0.6650\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.9321 - accuracy: 0.6796 - val_loss: 1.0880 - val_accuracy: 0.6650\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.8467 - accuracy: 0.7034 - val_loss: 1.1077 - val_accuracy: 0.6950\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.7993 - accuracy: 0.7322 - val_loss: 1.1359 - val_accuracy: 0.6350\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 48s 2s/step - loss: 0.8067 - accuracy: 0.7272 - val_loss: 1.0322 - val_accuracy: 0.6850\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 46s 2s/step - loss: 0.8377 - accuracy: 0.7309 - val_loss: 1.0857 - val_accuracy: 0.6850\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.6937 - accuracy: 0.7635 - val_loss: 1.1906 - val_accuracy: 0.6800\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.6668 - accuracy: 0.7760 - val_loss: 1.0281 - val_accuracy: 0.7050\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.7392 - accuracy: 0.7635 - val_loss: 1.3345 - val_accuracy: 0.5950\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 48s 2s/step - loss: 0.7210 - accuracy: 0.7647 - val_loss: 1.1026 - val_accuracy: 0.7000\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.6293 - accuracy: 0.7885 - val_loss: 1.1109 - val_accuracy: 0.6900\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.5806 - accuracy: 0.8223 - val_loss: 1.1266 - val_accuracy: 0.6900\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.5942 - accuracy: 0.7960 - val_loss: 1.0906 - val_accuracy: 0.7000\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 47s 2s/step - loss: 0.5546 - accuracy: 0.8223 - val_loss: 1.1151 - val_accuracy: 0.7050\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.4855 - accuracy: 0.8586 - val_loss: 1.1920 - val_accuracy: 0.6950\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.4703 - accuracy: 0.8611 - val_loss: 1.4242 - val_accuracy: 0.6600\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 46s 2s/step - loss: 0.4879 - accuracy: 0.8423 - val_loss: 1.1675 - val_accuracy: 0.6850\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 48s 2s/step - loss: 0.4240 - accuracy: 0.8748 - val_loss: 1.2651 - val_accuracy: 0.7050\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.4597 - accuracy: 0.8573 - val_loss: 1.1719 - val_accuracy: 0.7250\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.4823 - accuracy: 0.8398 - val_loss: 1.2350 - val_accuracy: 0.6400\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.4303 - accuracy: 0.8636 - val_loss: 1.2894 - val_accuracy: 0.6700\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 47s 2s/step - loss: 0.5040 - accuracy: 0.8373 - val_loss: 1.3469 - val_accuracy: 0.6300\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.3904 - accuracy: 0.8874 - val_loss: 1.2353 - val_accuracy: 0.6600\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.3679 - accuracy: 0.8899 - val_loss: 1.3244 - val_accuracy: 0.6700\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.4162 - accuracy: 0.8698 - val_loss: 1.4071 - val_accuracy: 0.6600\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 48s 2s/step - loss: 0.3700 - accuracy: 0.8949 - val_loss: 1.3244 - val_accuracy: 0.6800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e20002282b0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score , confusion_matrix , classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred , axis = 1)\n",
        "y_test2 = np.argmax(y_test , axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PBjxiP8pNsZ",
        "outputId": "f1e0c8c8-8595-458e-f00a-69c10f960b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 3s 343ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_score(y_test2 , y_pred)*100 ,'%')\n",
        "print(confusion_matrix(y_test2 , y_pred))\n",
        "print(classification_report(y_test2 , y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vve9MdeupeLC",
        "outputId": "5ec4a9b6-3f12-453c-c631-4cc863c8109a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68.0 %\n",
            "[[16  0  1  2  0  0  0  0  1  1]\n",
            " [ 0 12  0  0  0  0  0  0  0  0]\n",
            " [ 1  0 12  5  0  2  0  1  1  2]\n",
            " [ 0  0  0 17  1  0  1  2  0  1]\n",
            " [ 0  0  0  0 12  0  0  1  1  1]\n",
            " [ 3  2  1  0  0 19  0  0  2  0]\n",
            " [ 0  0  0  2  1  0 14  0  0  1]\n",
            " [ 0  0  1  1  0  0  0 16  1  0]\n",
            " [ 0  0  1  1  1  0  0  1 15  3]\n",
            " [ 2  0  0  8  2  0  3  2  0  3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.76      0.74        21\n",
            "           1       0.86      1.00      0.92        12\n",
            "           2       0.75      0.50      0.60        24\n",
            "           3       0.47      0.77      0.59        22\n",
            "           4       0.71      0.80      0.75        15\n",
            "           5       0.90      0.70      0.79        27\n",
            "           6       0.78      0.78      0.78        18\n",
            "           7       0.70      0.84      0.76        19\n",
            "           8       0.71      0.68      0.70        22\n",
            "           9       0.25      0.15      0.19        20\n",
            "\n",
            "    accuracy                           0.68       200\n",
            "   macro avg       0.69      0.70      0.68       200\n",
            "weighted avg       0.68      0.68      0.67       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install audiomentations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZofu_tmTMHM",
        "outputId": "d5f251bf-6290-4304-9730-692e521a8b3d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting audiomentations\n",
            "  Downloading audiomentations-0.36.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (1.25.2)\n",
            "Requirement already satisfied: librosa!=0.10.0,<0.11.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (0.10.2.post1)\n",
            "Collecting scipy<1.13,>=1.4 (from audiomentations)\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soxr<1.0.0,>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from audiomentations) (0.3.7)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.3.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2024.7.4)\n",
            "Downloading audiomentations-0.36.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, audiomentations\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xgboost 2.1.0 requires nvidia-nccl-cu12; platform_system == \"Linux\" and platform_machine != \"aarch64\", which is not installed.\n",
            "osqp 0.6.7.post0 requires scipy!=1.12.0,>=0.13.2, but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed audiomentations-0.36.0 scipy-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift"
      ],
      "metadata": {
        "id": "hNvrBysj-zgM"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augment = Compose([\n",
        "    AddGaussianNoise(min_amplitude = 0.001 ,\n",
        "                     max_amplitude = 0.015 ,\n",
        "                     p = 0.5) ,\n",
        "    TimeStretch(min_rate = 0.8 ,\n",
        "                max_rate = 1.25 ,\n",
        "                p = 0.5 ),\n",
        "    PitchShift(min_semitones = -4 ,\n",
        "               max_semitones = 4 ,\n",
        "               p = 0.5)\n",
        "])"
      ],
      "metadata": {
        "id": "SsiR3h_V_Ln2"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_audio(y):\n",
        "    # Apply augmentation\n",
        "    y_augmented = augment(samples=y, sample_rate=22050)\n",
        "    return y_augmented"
      ],
      "metadata": {
        "id": "5PVxcw4L_rF-"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features2(file_name, fixed_length=128):\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
        "        # Apply augmentation\n",
        "        audio = augment_audio(audio)\n",
        "        # Extract Mel spectrogram features\n",
        "        mel = librosa.feature.melspectrogram(y=audio, sr=sample_rate)\n",
        "        mel_db = librosa.power_to_db(mel)\n",
        "\n",
        "        # Pad or truncate to fixed length\n",
        "        if mel_db.shape[1] > fixed_length:\n",
        "            mel_db = mel_db[:, :fixed_length]\n",
        "        else:\n",
        "            padding = fixed_length - mel_db.shape[1]\n",
        "            mel_db = np.pad(mel_db, ((0, 0), (0, padding)), mode='constant')\n",
        "\n",
        "        return mel_db\n",
        "    except (sf.LibsndfileError, audioread.NoBackendError) as e:\n",
        "        print(f\"Error: {file_name} - {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "FPbzPpLNAPzG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "for class_idx, class_name in enumerate(gen_name):\n",
        "    class_dir = os.path.join(path, class_name)\n",
        "    for file_name in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, file_name)\n",
        "        features = extract_features2(file_path)\n",
        "        if features is not None:\n",
        "            x_data.append(features)\n",
        "            y_data.append(class_idx)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D8hHcEOAm6v",
        "outputId": "696c5c84-0053-4ac5-99bc-373206d1d310"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-6bf8d1100b43>:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: /content/Data/genres_original/jazz/jazz.00054.wav - \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = np.array(x_data)\n",
        "y_data = to_categorical(np.array(y_data), num_classes=len(gen_name))"
      ],
      "metadata": {
        "id": "SCVNZ2XkBZ_y"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, Y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "Px6lLfFdDmpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K9U-wIbGH6y",
        "outputId": "cf40b877-5db9-4498-c05e-5018b93bffe5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(799, 128, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=((128, 128 , 1)), kernel_regularizer=l2(r_s)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(r_s)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(r_s)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_regularizer=l2(r_s)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l2(r_s)))\n",
        "model.add(Dense(10, activation='softmax', kernel_regularizer=l2(r_s)))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "FkFn_8kBDq2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veIG_JrEGCEV",
        "outputId": "e3fe2d18-b1e1-4255-db5f-d5c38cdc6af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_11 (Conv2D)          (None, 126, 126, 32)      320       \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 126, 126, 32)      128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 63, 63, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 61, 61, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPooli  (None, 30, 30, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 28, 28, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPooli  (None, 14, 14, 128)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               3211392   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3313866 (12.64 MB)\n",
            "Trainable params: 3313418 (12.64 MB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, Y_train, epochs=50, validation_data=(x_val, y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBir0KStGQp4",
        "outputId": "253f4812-2bcb-43fa-8452-700667cc1ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 34s 1s/step - loss: 2.7183 - accuracy: 0.1502 - val_loss: 2.3879 - val_accuracy: 0.1450\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 2.1233 - accuracy: 0.2591 - val_loss: 2.3307 - val_accuracy: 0.1150\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 29s 1s/step - loss: 1.9094 - accuracy: 0.3304 - val_loss: 2.3209 - val_accuracy: 0.1200\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.7181 - accuracy: 0.4143 - val_loss: 2.2942 - val_accuracy: 0.1400\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.6327 - accuracy: 0.4155 - val_loss: 2.1989 - val_accuracy: 0.1950\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.3983 - accuracy: 0.5156 - val_loss: 2.1163 - val_accuracy: 0.2450\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 1.2411 - accuracy: 0.6083 - val_loss: 1.9582 - val_accuracy: 0.3200\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 30s 1s/step - loss: 1.0900 - accuracy: 0.6395 - val_loss: 1.8686 - val_accuracy: 0.3900\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 30s 1s/step - loss: 1.0240 - accuracy: 0.6658 - val_loss: 1.8482 - val_accuracy: 0.3750\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.9047 - accuracy: 0.7034 - val_loss: 1.7815 - val_accuracy: 0.3950\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.7263 - accuracy: 0.7860 - val_loss: 1.7251 - val_accuracy: 0.4050\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.7140 - accuracy: 0.7710 - val_loss: 1.8114 - val_accuracy: 0.4000\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 35s 1s/step - loss: 0.5847 - accuracy: 0.8348 - val_loss: 1.7452 - val_accuracy: 0.4100\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.5410 - accuracy: 0.8398 - val_loss: 1.7018 - val_accuracy: 0.3850\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.4621 - accuracy: 0.8861 - val_loss: 1.7993 - val_accuracy: 0.4250\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.4227 - accuracy: 0.8899 - val_loss: 1.7555 - val_accuracy: 0.4150\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.4019 - accuracy: 0.8836 - val_loss: 1.8163 - val_accuracy: 0.3900\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.4002 - accuracy: 0.8886 - val_loss: 1.7421 - val_accuracy: 0.4150\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 29s 1s/step - loss: 0.3492 - accuracy: 0.9011 - val_loss: 1.7203 - val_accuracy: 0.4100\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.3263 - accuracy: 0.9237 - val_loss: 1.8636 - val_accuracy: 0.3900\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.3356 - accuracy: 0.9149 - val_loss: 1.9391 - val_accuracy: 0.3750\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.2759 - accuracy: 0.9312 - val_loss: 1.7441 - val_accuracy: 0.4200\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.2499 - accuracy: 0.9387 - val_loss: 1.9699 - val_accuracy: 0.4150\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.2184 - accuracy: 0.9462 - val_loss: 1.7561 - val_accuracy: 0.4400\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.2349 - accuracy: 0.9412 - val_loss: 1.9953 - val_accuracy: 0.4000\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.1922 - accuracy: 0.9625 - val_loss: 1.8943 - val_accuracy: 0.4350\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.2247 - accuracy: 0.9387 - val_loss: 2.0365 - val_accuracy: 0.4000\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.2369 - accuracy: 0.9399 - val_loss: 2.0504 - val_accuracy: 0.4200\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.1658 - accuracy: 0.9737 - val_loss: 1.9288 - val_accuracy: 0.4100\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 34s 1s/step - loss: 0.1757 - accuracy: 0.9637 - val_loss: 1.9685 - val_accuracy: 0.4550\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 29s 1s/step - loss: 0.1678 - accuracy: 0.9625 - val_loss: 1.9940 - val_accuracy: 0.4350\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 29s 1s/step - loss: 0.1587 - accuracy: 0.9712 - val_loss: 2.0904 - val_accuracy: 0.4400\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.1727 - accuracy: 0.9637 - val_loss: 2.2961 - val_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.1508 - accuracy: 0.9725 - val_loss: 2.2082 - val_accuracy: 0.4200\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.1576 - accuracy: 0.9662 - val_loss: 2.2626 - val_accuracy: 0.4400\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.1494 - accuracy: 0.9712 - val_loss: 2.2647 - val_accuracy: 0.4250\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.1675 - accuracy: 0.9549 - val_loss: 2.0929 - val_accuracy: 0.4500\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.1449 - accuracy: 0.9712 - val_loss: 1.9915 - val_accuracy: 0.4450\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.1451 - accuracy: 0.9687 - val_loss: 1.9823 - val_accuracy: 0.4400\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 29s 1s/step - loss: 0.1236 - accuracy: 0.9750 - val_loss: 2.2272 - val_accuracy: 0.4300\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.1236 - accuracy: 0.9775 - val_loss: 2.0204 - val_accuracy: 0.4350\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.1465 - accuracy: 0.9662 - val_loss: 2.2018 - val_accuracy: 0.4100\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.1439 - accuracy: 0.9675 - val_loss: 2.2003 - val_accuracy: 0.3900\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.1301 - accuracy: 0.9712 - val_loss: 2.4409 - val_accuracy: 0.4400\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.1305 - accuracy: 0.9712 - val_loss: 2.3048 - val_accuracy: 0.4450\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.1229 - accuracy: 0.9775 - val_loss: 2.3269 - val_accuracy: 0.4050\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.1236 - accuracy: 0.9775 - val_loss: 2.0932 - val_accuracy: 0.4550\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.1343 - accuracy: 0.9712 - val_loss: 2.4332 - val_accuracy: 0.4250\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.1258 - accuracy: 0.9775 - val_loss: 2.3497 - val_accuracy: 0.4150\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 33s 1s/step - loss: 0.1336 - accuracy: 0.9712 - val_loss: 2.3321 - val_accuracy: 0.3850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phL2fTnWGVA-",
        "outputId": "98f11aa1-9b9e-4c58-dce3-d701ee67fd6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(799, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print accutrcat confession matrix\n",
        "\n",
        "y_pred = model.predict(x_val)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_test2 = np.argmax(y_val, axis=1)\n",
        "print(accuracy_score(y_test2, y_pred) * 100, '%')\n",
        "print(confusion_matrix(y_test2, y_pred))\n",
        "print(classification_report(y_test2, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rDHn2juGf8k",
        "outputId": "bdfc1b1f-5bf2-4c9b-b070-b64613bc7c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 2s 215ms/step\n",
            "38.5 %\n",
            "[[ 5  4  1  1  1  4  1  1  1  2]\n",
            " [ 0 11  0  1  0  0  0  0  0  0]\n",
            " [ 1  9  2  5  0  2  1  0  0  4]\n",
            " [ 1  0  1  6  1  0  4  3  1  5]\n",
            " [ 0  0  0  1  9  0  3  0  1  1]\n",
            " [ 2 10  0  0  1 11  0  0  2  1]\n",
            " [ 0  0  0  0  1  0 17  0  0  0]\n",
            " [ 0  1  1  5  4  1  0  4  2  1]\n",
            " [ 0  0  0  4  7  0  0  0  8  3]\n",
            " [ 2  3  1  4  1  0  4  0  1  4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.24      0.31        21\n",
            "           1       0.29      0.92      0.44        12\n",
            "           2       0.33      0.08      0.13        24\n",
            "           3       0.22      0.27      0.24        22\n",
            "           4       0.36      0.60      0.45        15\n",
            "           5       0.61      0.41      0.49        27\n",
            "           6       0.57      0.94      0.71        18\n",
            "           7       0.50      0.21      0.30        19\n",
            "           8       0.50      0.36      0.42        22\n",
            "           9       0.19      0.20      0.20        20\n",
            "\n",
            "    accuracy                           0.38       200\n",
            "   macro avg       0.40      0.42      0.37       200\n",
            "weighted avg       0.41      0.39      0.36       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LEts try a RNN"
      ],
      "metadata": {
        "id": "9d01Le5ZM-9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM , Reshape , Bidirectional"
      ],
      "metadata": {
        "id": "__52vQu5NPUn"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNN = Sequential()\n",
        "RNN.add(InputLayer(input_shape=(128, 128, 1)))\n",
        "RNN.add(Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.0001)))\n",
        "RNN.add(BatchNormalization())\n",
        "RNN.add(MaxPooling2D((2, 2)))\n",
        "RNN.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.0001)))\n",
        "RNN.add(BatchNormalization())\n",
        "RNN.add(MaxPooling2D((2, 2)))\n",
        "RNN.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.0001)))\n",
        "RNN.add(BatchNormalization())\n",
        "RNN.add(MaxPooling2D((2, 2)))\n",
        "# # RNN.add(Flatten())\n",
        "# RNN.add(Reshape((14 * 14, 128)))\n",
        "# RNN.add(LSTM(128, return_sequences=True))\n",
        "# RNN.add(LSTM(128))\n",
        "RNN.add(Flatten())\n",
        "RNN.add(Dense(256, activation='relu', kernel_regularizer=l2(0.0001)))\n",
        "RNN.add(Dropout(0.5))\n",
        "RNN.add(Dense(128, activation='relu', kernel_regularizer=l2(0.0001)))\n",
        "RNN.add(Dropout(0.5))\n",
        "RNN.add(Dense(64, activation='relu', kernel_regularizer=l2(0.0001)))\n",
        "RNN.add(Dense(10, activation='softmax', kernel_regularizer=l2(0.0001)))\n",
        "\n",
        "# Compile the RNN\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "RNN.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "Ka4QeTfSMpEy"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nE2gzmrOB9k",
        "outputId": "9a9e6638-4945-4a01-afe9-4bb063d30e76"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 126, 126, 32)      320       \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 126, 126, 32)      128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 63, 63, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 61, 61, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 30, 30, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 28, 28, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 14, 14, 128)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " reshape_3 (Reshape)         (None, 196, 128)          0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 196, 128)          131584    \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 431562 (1.65 MB)\n",
            "Trainable params: 431114 (1.64 MB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RNN.fit(X_train , y_train , epochs = 50 , batch_size = 32 , validation_data = (X_test , y_test))"
      ],
      "metadata": {
        "id": "N-5aFt6XQ581",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3d4177-d334-4949-f229-909d4e578f4f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 67s 3s/step - loss: 1.4155 - accuracy: 0.4944 - val_loss: 2.6398 - val_accuracy: 0.1150\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 1.4072 - accuracy: 0.4969 - val_loss: 2.5198 - val_accuracy: 0.1200\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 1.3982 - accuracy: 0.5031 - val_loss: 2.4338 - val_accuracy: 0.1400\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 1.4256 - accuracy: 0.5131 - val_loss: 2.4370 - val_accuracy: 0.1450\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 58s 2s/step - loss: 1.3771 - accuracy: 0.5319 - val_loss: 2.3549 - val_accuracy: 0.1850\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 62s 3s/step - loss: 1.3398 - accuracy: 0.5244 - val_loss: 2.4821 - val_accuracy: 0.1350\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 56s 2s/step - loss: 1.2906 - accuracy: 0.5544 - val_loss: 2.4079 - val_accuracy: 0.1500\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 62s 3s/step - loss: 1.2312 - accuracy: 0.5632 - val_loss: 2.4641 - val_accuracy: 0.1250\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 57s 2s/step - loss: 1.3051 - accuracy: 0.5457 - val_loss: 2.4251 - val_accuracy: 0.1400\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 58s 2s/step - loss: 1.1880 - accuracy: 0.5832 - val_loss: 2.4981 - val_accuracy: 0.1100\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 57s 2s/step - loss: 1.1776 - accuracy: 0.5795 - val_loss: 2.6357 - val_accuracy: 0.0950\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 57s 2s/step - loss: 1.1765 - accuracy: 0.5907 - val_loss: 2.4999 - val_accuracy: 0.1500\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 68s 3s/step - loss: 1.1400 - accuracy: 0.5957 - val_loss: 2.4124 - val_accuracy: 0.1550\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 1.0883 - accuracy: 0.6195 - val_loss: 2.4657 - val_accuracy: 0.1350\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 1.0835 - accuracy: 0.6395 - val_loss: 2.5076 - val_accuracy: 0.1450\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 1.0566 - accuracy: 0.6408 - val_loss: 2.5538 - val_accuracy: 0.1150\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 1.0106 - accuracy: 0.6458 - val_loss: 2.5549 - val_accuracy: 0.1450\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.9739 - accuracy: 0.6746 - val_loss: 2.3435 - val_accuracy: 0.2200\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.9522 - accuracy: 0.6746 - val_loss: 2.3599 - val_accuracy: 0.1900\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 60s 2s/step - loss: 1.0346 - accuracy: 0.6546 - val_loss: 2.2489 - val_accuracy: 0.2400\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 60s 2s/step - loss: 0.9157 - accuracy: 0.6921 - val_loss: 2.3286 - val_accuracy: 0.2150\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.8354 - accuracy: 0.7171 - val_loss: 2.3175 - val_accuracy: 0.1950\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.8072 - accuracy: 0.7334 - val_loss: 2.4090 - val_accuracy: 0.1650\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 60s 2s/step - loss: 0.8526 - accuracy: 0.7209 - val_loss: 2.2955 - val_accuracy: 0.1800\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.7769 - accuracy: 0.7284 - val_loss: 2.2874 - val_accuracy: 0.2000\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 60s 2s/step - loss: 0.8128 - accuracy: 0.7409 - val_loss: 2.7672 - val_accuracy: 0.1200\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.8022 - accuracy: 0.7397 - val_loss: 2.8950 - val_accuracy: 0.0950\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.7268 - accuracy: 0.7647 - val_loss: 2.4259 - val_accuracy: 0.1450\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 60s 2s/step - loss: 0.7065 - accuracy: 0.7985 - val_loss: 2.5748 - val_accuracy: 0.1450\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.7922 - accuracy: 0.7534 - val_loss: 2.3380 - val_accuracy: 0.1850\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.6688 - accuracy: 0.7922 - val_loss: 2.9619 - val_accuracy: 0.1450\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 60s 2s/step - loss: 0.6022 - accuracy: 0.8185 - val_loss: 3.8211 - val_accuracy: 0.1100\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.5999 - accuracy: 0.8160 - val_loss: 3.0392 - val_accuracy: 0.1300\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 58s 2s/step - loss: 0.6581 - accuracy: 0.7885 - val_loss: 3.3555 - val_accuracy: 0.1050\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.5282 - accuracy: 0.8611 - val_loss: 2.7849 - val_accuracy: 0.1600\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.4808 - accuracy: 0.8698 - val_loss: 3.7506 - val_accuracy: 0.1400\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.4954 - accuracy: 0.8736 - val_loss: 3.5077 - val_accuracy: 0.1450\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 56s 2s/step - loss: 0.5233 - accuracy: 0.8561 - val_loss: 3.6012 - val_accuracy: 0.1100\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.5213 - accuracy: 0.8586 - val_loss: 2.7840 - val_accuracy: 0.1500\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.5281 - accuracy: 0.8573 - val_loss: 3.5054 - val_accuracy: 0.1300\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 55s 2s/step - loss: 0.4884 - accuracy: 0.8661 - val_loss: 2.6894 - val_accuracy: 0.1850\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.4628 - accuracy: 0.8849 - val_loss: 3.4333 - val_accuracy: 0.1400\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.4569 - accuracy: 0.8736 - val_loss: 4.1866 - val_accuracy: 0.1100\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.4142 - accuracy: 0.8836 - val_loss: 4.5935 - val_accuracy: 0.1200\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.3908 - accuracy: 0.9049 - val_loss: 4.6755 - val_accuracy: 0.1050\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.5473 - accuracy: 0.8548 - val_loss: 3.2499 - val_accuracy: 0.1350\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 60s 2s/step - loss: 0.3998 - accuracy: 0.9024 - val_loss: 4.1515 - val_accuracy: 0.1350\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 57s 2s/step - loss: 0.3738 - accuracy: 0.9049 - val_loss: 4.7278 - val_accuracy: 0.1200\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 58s 2s/step - loss: 0.3007 - accuracy: 0.9362 - val_loss: 4.9072 - val_accuracy: 0.1200\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.3049 - accuracy: 0.9274 - val_loss: 4.5354 - val_accuracy: 0.1150\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7dc281e770a0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print the accuracy precision and confusion matrix\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# ... (your existing code) ...\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = RNN.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
      ],
      "metadata": {
        "id": "HEwslf23REIC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ffc833d-98a3-4363-8a3a-3b9a0191e025"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 13s 1s/step\n",
            "Accuracy: 0.575\n",
            "Precision: 0.5605185015147929\n",
            "Recall: 0.575\n",
            "F1-score: 0.5562677460719151\n",
            "Confusion Matrix:\n",
            " [[15  0  3  1  1  1  0  0  0  0]\n",
            " [ 0 11  0  0  0  1  0  0  0  0]\n",
            " [ 1  1  8  3  1  3  0  1  5  1]\n",
            " [ 0  0  0  6  8  0  0  4  2  2]\n",
            " [ 0  0  1  2  7  0  0  3  2  0]\n",
            " [ 0  3  1  0  0 22  0  1  0  0]\n",
            " [ 0  0  0  0  0  0 18  0  0  0]\n",
            " [ 0  0  3  1  2  0  0 13  0  0]\n",
            " [ 1  0  3  1  3  0  0  0 13  1]\n",
            " [ 1  0  0  6  3  2  5  0  1  2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fwYVvJKx6hy",
        "outputId": "e3133f39-4ffd-4691-fc31-5347d8135b19"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Add\n",
        "\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "def create_model(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Convolutional layers\n",
        "    x = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(r_s))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(r_s))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(r_s))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    # Flatten the conv output\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Reshape for Transformer\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = tf.expand_dims(x, axis=1)\n",
        "\n",
        "    # Transformer block\n",
        "    transformer_block = TransformerBlock(embed_dim=256, num_heads=8, ff_dim=512)\n",
        "    x = transformer_block(x)\n",
        "    x = tf.squeeze(x, axis=1)\n",
        "\n",
        "    # Dense layers\n",
        "    x = Dense(128, activation='relu', kernel_regularizer=l2(r_s))(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(64, activation='relu', kernel_regularizer=l2(r_s))(x)\n",
        "    outputs = Dense(num_classes, activation='softmax', kernel_regularizer=l2(r_s))(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Parameters\n",
        "input_shape = (128, 128, 1)\n",
        "num_classes = 10\n",
        "r_s = 0.01\n",
        "\n",
        "# Create the model\n",
        "model = create_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR68tHHl8K1d",
        "outputId": "c1f8d7d8-9f8e-4c96-fb1f-67989c500321"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 1)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 126, 126, 32)      320       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 126, 126, 32)      128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 61, 61, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 28, 28, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               6422784   \n",
            "                                                                 \n",
            " tf.expand_dims (TFOpLambda  (None, 1, 256)            0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " transformer_block (Transfo  (None, 1, 256)            2367488   \n",
            " rmerBlock)                                                      \n",
            "                                                                 \n",
            " tf.compat.v1.squeeze (TFOp  (None, 256)               0         \n",
            " Lambda)                                                         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8925642 (34.05 MB)\n",
            "Trainable params: 8925194 (34.05 MB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train , y_train , epochs = 50 , batch_size = 32 , validation_data = (X_test , y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85vY9e5-87rV",
        "outputId": "54a7a780-3256-44b4-e6d5-a65892c00e6a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 53s 2s/step - loss: 6.2128 - accuracy: 0.2178 - val_loss: 6.6306 - val_accuracy: 0.1050\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 41s 2s/step - loss: 5.8093 - accuracy: 0.3567 - val_loss: 6.6768 - val_accuracy: 0.1000\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 39s 2s/step - loss: 5.5423 - accuracy: 0.4443 - val_loss: 6.8330 - val_accuracy: 0.0900\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 40s 2s/step - loss: 5.1368 - accuracy: 0.5732 - val_loss: 6.7965 - val_accuracy: 0.0900\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 43s 2s/step - loss: 4.7478 - accuracy: 0.7059 - val_loss: 6.7181 - val_accuracy: 0.0900\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 39s 2s/step - loss: 4.4923 - accuracy: 0.7735 - val_loss: 6.6788 - val_accuracy: 0.0900\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 43s 2s/step - loss: 4.1272 - accuracy: 0.9111 - val_loss: 6.6778 - val_accuracy: 0.0900\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 53s 2s/step - loss: 3.9454 - accuracy: 0.9424 - val_loss: 7.0899 - val_accuracy: 0.0900\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 37s 2s/step - loss: 3.7967 - accuracy: 0.9812 - val_loss: 7.4540 - val_accuracy: 0.0900\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 39s 2s/step - loss: 3.7039 - accuracy: 0.9912 - val_loss: 7.6155 - val_accuracy: 0.0900\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 39s 2s/step - loss: 3.6272 - accuracy: 0.9950 - val_loss: 7.8240 - val_accuracy: 0.0900\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 38s 2s/step - loss: 3.5710 - accuracy: 0.9962 - val_loss: 8.0984 - val_accuracy: 0.0900\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 40s 2s/step - loss: 3.5152 - accuracy: 0.9987 - val_loss: 8.2634 - val_accuracy: 0.0900\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 39s 2s/step - loss: 3.4634 - accuracy: 0.9987 - val_loss: 8.2262 - val_accuracy: 0.0900\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 38s 2s/step - loss: 3.4119 - accuracy: 0.9987 - val_loss: 8.3434 - val_accuracy: 0.0900\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 39s 2s/step - loss: 3.3605 - accuracy: 0.9962 - val_loss: 8.4188 - val_accuracy: 0.0900\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 38s 2s/step - loss: 3.3022 - accuracy: 0.9987 - val_loss: 8.0529 - val_accuracy: 0.0950\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 39s 2s/step - loss: 3.2482 - accuracy: 1.0000 - val_loss: 8.1732 - val_accuracy: 0.1050\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 42s 2s/step - loss: 3.1979 - accuracy: 0.9987 - val_loss: 7.3730 - val_accuracy: 0.1450\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 40s 2s/step - loss: 3.1471 - accuracy: 0.9975 - val_loss: 7.0928 - val_accuracy: 0.1950\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 37s 1s/step - loss: 3.0941 - accuracy: 0.9975 - val_loss: 6.5745 - val_accuracy: 0.2350\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 40s 2s/step - loss: 3.0449 - accuracy: 0.9975 - val_loss: 6.3433 - val_accuracy: 0.2700\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 46s 2s/step - loss: 2.9877 - accuracy: 0.9987 - val_loss: 5.7063 - val_accuracy: 0.3400\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 38s 2s/step - loss: 2.9378 - accuracy: 0.9975 - val_loss: 5.4002 - val_accuracy: 0.4300\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 38s 1s/step - loss: 2.8845 - accuracy: 0.9987 - val_loss: 4.9881 - val_accuracy: 0.4850\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 39s 2s/step - loss: 2.8292 - accuracy: 1.0000 - val_loss: 4.6066 - val_accuracy: 0.5250\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 38s 2s/step - loss: 2.7832 - accuracy: 0.9975 - val_loss: 4.3848 - val_accuracy: 0.5550\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 40s 2s/step - loss: 2.7322 - accuracy: 0.9987 - val_loss: 4.1643 - val_accuracy: 0.5900\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 40s 2s/step - loss: 2.6798 - accuracy: 0.9975 - val_loss: 3.9923 - val_accuracy: 0.6150\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 37s 1s/step - loss: 2.6289 - accuracy: 0.9975 - val_loss: 3.9326 - val_accuracy: 0.6300\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 40s 2s/step - loss: 2.5825 - accuracy: 0.9975 - val_loss: 3.7471 - val_accuracy: 0.6700\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 41s 2s/step - loss: 2.5262 - accuracy: 0.9987 - val_loss: 3.7905 - val_accuracy: 0.6600\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 37s 1s/step - loss: 2.4799 - accuracy: 0.9987 - val_loss: 3.6387 - val_accuracy: 0.6500\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 42s 2s/step - loss: 2.4287 - accuracy: 0.9987 - val_loss: 3.5260 - val_accuracy: 0.6550\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 42s 2s/step - loss: 2.3805 - accuracy: 0.9975 - val_loss: 3.4563 - val_accuracy: 0.6700\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 38s 2s/step - loss: 2.3335 - accuracy: 0.9975 - val_loss: 3.4683 - val_accuracy: 0.6550\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 39s 2s/step - loss: 2.2841 - accuracy: 0.9987 - val_loss: 3.3522 - val_accuracy: 0.6650\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 39s 2s/step - loss: 2.2359 - accuracy: 1.0000 - val_loss: 3.3236 - val_accuracy: 0.6650\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 44s 2s/step - loss: 2.1928 - accuracy: 0.9975 - val_loss: 3.2824 - val_accuracy: 0.6500\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 37s 1s/step - loss: 2.1480 - accuracy: 0.9975 - val_loss: 3.2251 - val_accuracy: 0.6300\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 39s 2s/step - loss: 2.0991 - accuracy: 1.0000 - val_loss: 3.1068 - val_accuracy: 0.7000\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 38s 2s/step - loss: 2.0572 - accuracy: 0.9987 - val_loss: 3.1279 - val_accuracy: 0.6750\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 39s 2s/step - loss: 2.0092 - accuracy: 0.9987 - val_loss: 3.1142 - val_accuracy: 0.6750\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 41s 2s/step - loss: 1.9702 - accuracy: 0.9975 - val_loss: 3.0379 - val_accuracy: 0.6750\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 38s 2s/step - loss: 1.9242 - accuracy: 0.9975 - val_loss: 2.9154 - val_accuracy: 0.6800\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 40s 2s/step - loss: 1.8844 - accuracy: 0.9987 - val_loss: 3.0091 - val_accuracy: 0.6650\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 40s 2s/step - loss: 1.8419 - accuracy: 0.9987 - val_loss: 2.9008 - val_accuracy: 0.6800\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 37s 1s/step - loss: 1.8049 - accuracy: 0.9975 - val_loss: 2.8703 - val_accuracy: 0.6450\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 39s 2s/step - loss: 1.7604 - accuracy: 0.9987 - val_loss: 2.8743 - val_accuracy: 0.6700\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 39s 2s/step - loss: 1.7234 - accuracy: 0.9987 - val_loss: 2.7432 - val_accuracy: 0.6800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d875d332770>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print the accuracy , precision % and confusion matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# ... (your existing code) ...\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy * 100, \"%\")\n",
        "print(\"Precision:\", precision * 100, \"%\")\n",
        "print(\"Recall:\", recall * 100, \"%\")\n",
        "print(\"F1-score:\", f1 * 100, \"%\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKMciZvP9buX",
        "outputId": "b3a4d629-534b-43bd-803b-9b91a76cae7f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 4s 500ms/step\n",
            "Accuracy: 68.0 %\n",
            "Precision: 68.68764053579271 %\n",
            "Recall: 68.0 %\n",
            "F1-score: 67.37691464967023 %\n",
            "Confusion Matrix:\n",
            " [[14  0  2  0  0  3  0  0  2  0]\n",
            " [ 0 11  0  0  0  0  0  0  0  1]\n",
            " [ 2  0 17  1  0  0  0  3  0  1]\n",
            " [ 1  0  0 14  4  0  0  2  0  1]\n",
            " [ 0  0  0  0 11  0  3  0  1  0]\n",
            " [ 1  3  2  0  0 20  0  0  1  0]\n",
            " [ 0  0  0  0  1  0 16  0  0  1]\n",
            " [ 0  1  0  1  2  0  0 14  0  1]\n",
            " [ 1  0  1  2  4  0  0  0 14  0]\n",
            " [ 1  0  2  7  2  0  3  0  0  5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save the model to '/content'\n",
        "\n",
        "# ... (your existing code) ...\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/music_genre_transformer.h5')\n"
      ],
      "metadata": {
        "id": "Npf_2wr5FPbl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow_io as tfio\n",
        "yamnet = hub.load('https://tfhub.dev/google/yamnet/1')"
      ],
      "metadata": {
        "id": "d5zE7TxAFeon"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_wav(filename):\n",
        "  auido , sample_rate = librosa.load(filename , sr = 16000 , mono = True)\n",
        "  # auido = tf.cast(auido , tf.float32)\n",
        "  return auido"
      ],
      "metadata": {
        "id": "Uj-7CbUtHfXj"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features3(wav):\n",
        "  waveform = tf.convert_to_tensor(wav , dtype=tf.float32)\n",
        "  waveform = tf.reshape(waveform , [-1])\n",
        "  scores , embedding  , spectrogram = yamnet(waveform)\n",
        "  return embedding.numpy().flatten()"
      ],
      "metadata": {
        "id": "nxeci-__I7ue"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "source": [
        "# Check the shape of each element in 'nd'\n",
        "for i, element in enumerate(nd):\n",
        "    print(f\"Element {i} shape: {np.shape(element)}\")\n",
        "\n",
        "# If the shapes vary, consider padding or truncating the arrays\n",
        "# to make them uniform before converting to a NumPy array."
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGsUQ7z3Sf3u",
        "outputId": "930ba08a-466c-4b60-ccfc-1974f0cd92f6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element 0 shape: (63488,)\n",
            "Element 1 shape: (63488,)\n",
            "Element 2 shape: (63488,)\n",
            "Element 3 shape: (63488,)\n",
            "Element 4 shape: (63488,)\n",
            "Element 5 shape: (63488,)\n",
            "Element 6 shape: (63488,)\n",
            "Element 7 shape: (63488,)\n",
            "Element 8 shape: (63488,)\n",
            "Element 9 shape: (63488,)\n",
            "Element 10 shape: (63488,)\n",
            "Element 11 shape: (63488,)\n",
            "Element 12 shape: (63488,)\n",
            "Element 13 shape: (63488,)\n",
            "Element 14 shape: (63488,)\n",
            "Element 15 shape: (63488,)\n",
            "Element 16 shape: (63488,)\n",
            "Element 17 shape: (63488,)\n",
            "Element 18 shape: (63488,)\n",
            "Element 19 shape: (63488,)\n",
            "Element 20 shape: (63488,)\n",
            "Element 21 shape: (63488,)\n",
            "Element 22 shape: (63488,)\n",
            "Element 23 shape: (63488,)\n",
            "Element 24 shape: (63488,)\n",
            "Element 25 shape: (63488,)\n",
            "Element 26 shape: (63488,)\n",
            "Element 27 shape: (63488,)\n",
            "Element 28 shape: (63488,)\n",
            "Element 29 shape: (63488,)\n",
            "Element 30 shape: (63488,)\n",
            "Element 31 shape: (63488,)\n",
            "Element 32 shape: (63488,)\n",
            "Element 33 shape: (63488,)\n",
            "Element 34 shape: (63488,)\n",
            "Element 35 shape: (63488,)\n",
            "Element 36 shape: (63488,)\n",
            "Element 37 shape: (63488,)\n",
            "Element 38 shape: (63488,)\n",
            "Element 39 shape: (63488,)\n",
            "Element 40 shape: (63488,)\n",
            "Element 41 shape: (63488,)\n",
            "Element 42 shape: (63488,)\n",
            "Element 43 shape: (63488,)\n",
            "Element 44 shape: (63488,)\n",
            "Element 45 shape: (63488,)\n",
            "Element 46 shape: (63488,)\n",
            "Element 47 shape: (63488,)\n",
            "Element 48 shape: (63488,)\n",
            "Element 49 shape: (63488,)\n",
            "Element 50 shape: (63488,)\n",
            "Element 51 shape: (63488,)\n",
            "Element 52 shape: (63488,)\n",
            "Element 53 shape: (63488,)\n",
            "Element 54 shape: (63488,)\n",
            "Element 55 shape: (63488,)\n",
            "Element 56 shape: (63488,)\n",
            "Element 57 shape: (63488,)\n",
            "Element 58 shape: (63488,)\n",
            "Element 59 shape: (63488,)\n",
            "Element 60 shape: (63488,)\n",
            "Element 61 shape: (63488,)\n",
            "Element 62 shape: (63488,)\n",
            "Element 63 shape: (63488,)\n",
            "Element 64 shape: (63488,)\n",
            "Element 65 shape: (63488,)\n",
            "Element 66 shape: (63488,)\n",
            "Element 67 shape: (63488,)\n",
            "Element 68 shape: (63488,)\n",
            "Element 69 shape: (63488,)\n",
            "Element 70 shape: (63488,)\n",
            "Element 71 shape: (63488,)\n",
            "Element 72 shape: (63488,)\n",
            "Element 73 shape: (63488,)\n",
            "Element 74 shape: (63488,)\n",
            "Element 75 shape: (63488,)\n",
            "Element 76 shape: (63488,)\n",
            "Element 77 shape: (63488,)\n",
            "Element 78 shape: (63488,)\n",
            "Element 79 shape: (63488,)\n",
            "Element 80 shape: (63488,)\n",
            "Element 81 shape: (63488,)\n",
            "Element 82 shape: (63488,)\n",
            "Element 83 shape: (63488,)\n",
            "Element 84 shape: (63488,)\n",
            "Element 85 shape: (63488,)\n",
            "Element 86 shape: (63488,)\n",
            "Element 87 shape: (63488,)\n",
            "Element 88 shape: (63488,)\n",
            "Element 89 shape: (63488,)\n",
            "Element 90 shape: (63488,)\n",
            "Element 91 shape: (63488,)\n",
            "Element 92 shape: (63488,)\n",
            "Element 93 shape: (63488,)\n",
            "Element 94 shape: (63488,)\n",
            "Element 95 shape: (63488,)\n",
            "Element 96 shape: (63488,)\n",
            "Element 97 shape: (63488,)\n",
            "Element 98 shape: (63488,)\n",
            "Element 99 shape: (63488,)\n",
            "Element 100 shape: (63488,)\n",
            "Element 101 shape: (63488,)\n",
            "Element 102 shape: (63488,)\n",
            "Element 103 shape: (63488,)\n",
            "Element 104 shape: (63488,)\n",
            "Element 105 shape: (63488,)\n",
            "Element 106 shape: (63488,)\n",
            "Element 107 shape: (63488,)\n",
            "Element 108 shape: (63488,)\n",
            "Element 109 shape: (63488,)\n",
            "Element 110 shape: (63488,)\n",
            "Element 111 shape: (63488,)\n",
            "Element 112 shape: (63488,)\n",
            "Element 113 shape: (63488,)\n",
            "Element 114 shape: (63488,)\n",
            "Element 115 shape: (63488,)\n",
            "Element 116 shape: (63488,)\n",
            "Element 117 shape: (63488,)\n",
            "Element 118 shape: (63488,)\n",
            "Element 119 shape: (63488,)\n",
            "Element 120 shape: (63488,)\n",
            "Element 121 shape: (63488,)\n",
            "Element 122 shape: (63488,)\n",
            "Element 123 shape: (63488,)\n",
            "Element 124 shape: (63488,)\n",
            "Element 125 shape: (63488,)\n",
            "Element 126 shape: (63488,)\n",
            "Element 127 shape: (63488,)\n",
            "Element 128 shape: (63488,)\n",
            "Element 129 shape: (63488,)\n",
            "Element 130 shape: (63488,)\n",
            "Element 131 shape: (63488,)\n",
            "Element 132 shape: (63488,)\n",
            "Element 133 shape: (63488,)\n",
            "Element 134 shape: (63488,)\n",
            "Element 135 shape: (63488,)\n",
            "Element 136 shape: (63488,)\n",
            "Element 137 shape: (63488,)\n",
            "Element 138 shape: (63488,)\n",
            "Element 139 shape: (63488,)\n",
            "Element 140 shape: (63488,)\n",
            "Element 141 shape: (63488,)\n",
            "Element 142 shape: (64512,)\n",
            "Element 143 shape: (63488,)\n",
            "Element 144 shape: (63488,)\n",
            "Element 145 shape: (63488,)\n",
            "Element 146 shape: (63488,)\n",
            "Element 147 shape: (63488,)\n",
            "Element 148 shape: (63488,)\n",
            "Element 149 shape: (63488,)\n",
            "Element 150 shape: (63488,)\n",
            "Element 151 shape: (63488,)\n",
            "Element 152 shape: (63488,)\n",
            "Element 153 shape: (63488,)\n",
            "Element 154 shape: (63488,)\n",
            "Element 155 shape: (63488,)\n",
            "Element 156 shape: (63488,)\n",
            "Element 157 shape: (63488,)\n",
            "Element 158 shape: (63488,)\n",
            "Element 159 shape: (64512,)\n",
            "Element 160 shape: (63488,)\n",
            "Element 161 shape: (63488,)\n",
            "Element 162 shape: (63488,)\n",
            "Element 163 shape: (63488,)\n",
            "Element 164 shape: (63488,)\n",
            "Element 165 shape: (63488,)\n",
            "Element 166 shape: (63488,)\n",
            "Element 167 shape: (63488,)\n",
            "Element 168 shape: (63488,)\n",
            "Element 169 shape: (63488,)\n",
            "Element 170 shape: (63488,)\n",
            "Element 171 shape: (63488,)\n",
            "Element 172 shape: (63488,)\n",
            "Element 173 shape: (63488,)\n",
            "Element 174 shape: (63488,)\n",
            "Element 175 shape: (63488,)\n",
            "Element 176 shape: (63488,)\n",
            "Element 177 shape: (63488,)\n",
            "Element 178 shape: (63488,)\n",
            "Element 179 shape: (63488,)\n",
            "Element 180 shape: (63488,)\n",
            "Element 181 shape: (63488,)\n",
            "Element 182 shape: (64512,)\n",
            "Element 183 shape: (63488,)\n",
            "Element 184 shape: (63488,)\n",
            "Element 185 shape: (63488,)\n",
            "Element 186 shape: (63488,)\n",
            "Element 187 shape: (63488,)\n",
            "Element 188 shape: (63488,)\n",
            "Element 189 shape: (63488,)\n",
            "Element 190 shape: (63488,)\n",
            "Element 191 shape: (63488,)\n",
            "Element 192 shape: (63488,)\n",
            "Element 193 shape: (63488,)\n",
            "Element 194 shape: (63488,)\n",
            "Element 195 shape: (63488,)\n",
            "Element 196 shape: (63488,)\n",
            "Element 197 shape: (63488,)\n",
            "Element 198 shape: (63488,)\n",
            "Element 199 shape: (63488,)\n",
            "Element 200 shape: (63488,)\n",
            "Element 201 shape: (63488,)\n",
            "Element 202 shape: (63488,)\n",
            "Element 203 shape: (64512,)\n",
            "Element 204 shape: (63488,)\n",
            "Element 205 shape: (63488,)\n",
            "Element 206 shape: (63488,)\n",
            "Element 207 shape: (63488,)\n",
            "Element 208 shape: (63488,)\n",
            "Element 209 shape: (63488,)\n",
            "Element 210 shape: (63488,)\n",
            "Element 211 shape: (63488,)\n",
            "Element 212 shape: (63488,)\n",
            "Element 213 shape: (63488,)\n",
            "Element 214 shape: (63488,)\n",
            "Element 215 shape: (63488,)\n",
            "Element 216 shape: (63488,)\n",
            "Element 217 shape: (63488,)\n",
            "Element 218 shape: (63488,)\n",
            "Element 219 shape: (63488,)\n",
            "Element 220 shape: (63488,)\n",
            "Element 221 shape: (63488,)\n",
            "Element 222 shape: (63488,)\n",
            "Element 223 shape: (64512,)\n",
            "Element 224 shape: (63488,)\n",
            "Element 225 shape: (63488,)\n",
            "Element 226 shape: (63488,)\n",
            "Element 227 shape: (63488,)\n",
            "Element 228 shape: (63488,)\n",
            "Element 229 shape: (63488,)\n",
            "Element 230 shape: (63488,)\n",
            "Element 231 shape: (63488,)\n",
            "Element 232 shape: (63488,)\n",
            "Element 233 shape: (63488,)\n",
            "Element 234 shape: (63488,)\n",
            "Element 235 shape: (63488,)\n",
            "Element 236 shape: (63488,)\n",
            "Element 237 shape: (63488,)\n",
            "Element 238 shape: (63488,)\n",
            "Element 239 shape: (63488,)\n",
            "Element 240 shape: (63488,)\n",
            "Element 241 shape: (63488,)\n",
            "Element 242 shape: (63488,)\n",
            "Element 243 shape: (63488,)\n",
            "Element 244 shape: (63488,)\n",
            "Element 245 shape: (63488,)\n",
            "Element 246 shape: (63488,)\n",
            "Element 247 shape: (63488,)\n",
            "Element 248 shape: (63488,)\n",
            "Element 249 shape: (63488,)\n",
            "Element 250 shape: (63488,)\n",
            "Element 251 shape: (63488,)\n",
            "Element 252 shape: (63488,)\n",
            "Element 253 shape: (63488,)\n",
            "Element 254 shape: (63488,)\n",
            "Element 255 shape: (63488,)\n",
            "Element 256 shape: (63488,)\n",
            "Element 257 shape: (63488,)\n",
            "Element 258 shape: (63488,)\n",
            "Element 259 shape: (63488,)\n",
            "Element 260 shape: (63488,)\n",
            "Element 261 shape: (63488,)\n",
            "Element 262 shape: (63488,)\n",
            "Element 263 shape: (63488,)\n",
            "Element 264 shape: (63488,)\n",
            "Element 265 shape: (63488,)\n",
            "Element 266 shape: (63488,)\n",
            "Element 267 shape: (63488,)\n",
            "Element 268 shape: (63488,)\n",
            "Element 269 shape: (63488,)\n",
            "Element 270 shape: (63488,)\n",
            "Element 271 shape: (63488,)\n",
            "Element 272 shape: (63488,)\n",
            "Element 273 shape: (63488,)\n",
            "Element 274 shape: (63488,)\n",
            "Element 275 shape: (63488,)\n",
            "Element 276 shape: (63488,)\n",
            "Element 277 shape: (63488,)\n",
            "Element 278 shape: (63488,)\n",
            "Element 279 shape: (63488,)\n",
            "Element 280 shape: (63488,)\n",
            "Element 281 shape: (63488,)\n",
            "Element 282 shape: (63488,)\n",
            "Element 283 shape: (63488,)\n",
            "Element 284 shape: (63488,)\n",
            "Element 285 shape: (63488,)\n",
            "Element 286 shape: (63488,)\n",
            "Element 287 shape: (63488,)\n",
            "Element 288 shape: (63488,)\n",
            "Element 289 shape: (63488,)\n",
            "Element 290 shape: (63488,)\n",
            "Element 291 shape: (63488,)\n",
            "Element 292 shape: (63488,)\n",
            "Element 293 shape: (63488,)\n",
            "Element 294 shape: (63488,)\n",
            "Element 295 shape: (63488,)\n",
            "Element 296 shape: (63488,)\n",
            "Element 297 shape: (63488,)\n",
            "Element 298 shape: (63488,)\n",
            "Element 299 shape: (63488,)\n",
            "Element 300 shape: (63488,)\n",
            "Element 301 shape: (63488,)\n",
            "Element 302 shape: (63488,)\n",
            "Element 303 shape: (63488,)\n",
            "Element 304 shape: (63488,)\n",
            "Element 305 shape: (63488,)\n",
            "Element 306 shape: (63488,)\n",
            "Element 307 shape: (63488,)\n",
            "Element 308 shape: (63488,)\n",
            "Element 309 shape: (63488,)\n",
            "Element 310 shape: (63488,)\n",
            "Element 311 shape: (63488,)\n",
            "Element 312 shape: (63488,)\n",
            "Element 313 shape: (63488,)\n",
            "Element 314 shape: (63488,)\n",
            "Element 315 shape: (63488,)\n",
            "Element 316 shape: (63488,)\n",
            "Element 317 shape: (63488,)\n",
            "Element 318 shape: (63488,)\n",
            "Element 319 shape: (63488,)\n",
            "Element 320 shape: (63488,)\n",
            "Element 321 shape: (63488,)\n",
            "Element 322 shape: (63488,)\n",
            "Element 323 shape: (63488,)\n",
            "Element 324 shape: (63488,)\n",
            "Element 325 shape: (63488,)\n",
            "Element 326 shape: (63488,)\n",
            "Element 327 shape: (63488,)\n",
            "Element 328 shape: (63488,)\n",
            "Element 329 shape: (63488,)\n",
            "Element 330 shape: (63488,)\n",
            "Element 331 shape: (63488,)\n",
            "Element 332 shape: (63488,)\n",
            "Element 333 shape: (63488,)\n",
            "Element 334 shape: (64512,)\n",
            "Element 335 shape: (63488,)\n",
            "Element 336 shape: (63488,)\n",
            "Element 337 shape: (63488,)\n",
            "Element 338 shape: (63488,)\n",
            "Element 339 shape: (63488,)\n",
            "Element 340 shape: (63488,)\n",
            "Element 341 shape: (63488,)\n",
            "Element 342 shape: (63488,)\n",
            "Element 343 shape: (63488,)\n",
            "Element 344 shape: (63488,)\n",
            "Element 345 shape: (63488,)\n",
            "Element 346 shape: (63488,)\n",
            "Element 347 shape: (63488,)\n",
            "Element 348 shape: (63488,)\n",
            "Element 349 shape: (63488,)\n",
            "Element 350 shape: (63488,)\n",
            "Element 351 shape: (63488,)\n",
            "Element 352 shape: (63488,)\n",
            "Element 353 shape: (63488,)\n",
            "Element 354 shape: (63488,)\n",
            "Element 355 shape: (63488,)\n",
            "Element 356 shape: (63488,)\n",
            "Element 357 shape: (63488,)\n",
            "Element 358 shape: (63488,)\n",
            "Element 359 shape: (63488,)\n",
            "Element 360 shape: (63488,)\n",
            "Element 361 shape: (63488,)\n",
            "Element 362 shape: (63488,)\n",
            "Element 363 shape: (63488,)\n",
            "Element 364 shape: (63488,)\n",
            "Element 365 shape: (63488,)\n",
            "Element 366 shape: (63488,)\n",
            "Element 367 shape: (63488,)\n",
            "Element 368 shape: (63488,)\n",
            "Element 369 shape: (63488,)\n",
            "Element 370 shape: (63488,)\n",
            "Element 371 shape: (63488,)\n",
            "Element 372 shape: (63488,)\n",
            "Element 373 shape: (63488,)\n",
            "Element 374 shape: (63488,)\n",
            "Element 375 shape: (63488,)\n",
            "Element 376 shape: (63488,)\n",
            "Element 377 shape: (63488,)\n",
            "Element 378 shape: (63488,)\n",
            "Element 379 shape: (63488,)\n",
            "Element 380 shape: (63488,)\n",
            "Element 381 shape: (63488,)\n",
            "Element 382 shape: (63488,)\n",
            "Element 383 shape: (63488,)\n",
            "Element 384 shape: (63488,)\n",
            "Element 385 shape: (63488,)\n",
            "Element 386 shape: (63488,)\n",
            "Element 387 shape: (63488,)\n",
            "Element 388 shape: (63488,)\n",
            "Element 389 shape: (63488,)\n",
            "Element 390 shape: (64512,)\n",
            "Element 391 shape: (63488,)\n",
            "Element 392 shape: (63488,)\n",
            "Element 393 shape: (63488,)\n",
            "Element 394 shape: (63488,)\n",
            "Element 395 shape: (63488,)\n",
            "Element 396 shape: (63488,)\n",
            "Element 397 shape: (64512,)\n",
            "Element 398 shape: (63488,)\n",
            "Element 399 shape: (63488,)\n",
            "Element 400 shape: (64512,)\n",
            "Element 401 shape: (63488,)\n",
            "Element 402 shape: (63488,)\n",
            "Element 403 shape: (63488,)\n",
            "Element 404 shape: (63488,)\n",
            "Element 405 shape: (63488,)\n",
            "Element 406 shape: (63488,)\n",
            "Element 407 shape: (63488,)\n",
            "Element 408 shape: (63488,)\n",
            "Element 409 shape: (63488,)\n",
            "Element 410 shape: (64512,)\n",
            "Element 411 shape: (64512,)\n",
            "Element 412 shape: (63488,)\n",
            "Element 413 shape: (63488,)\n",
            "Element 414 shape: (63488,)\n",
            "Element 415 shape: (63488,)\n",
            "Element 416 shape: (64512,)\n",
            "Element 417 shape: (63488,)\n",
            "Element 418 shape: (63488,)\n",
            "Element 419 shape: (63488,)\n",
            "Element 420 shape: (63488,)\n",
            "Element 421 shape: (63488,)\n",
            "Element 422 shape: (64512,)\n",
            "Element 423 shape: (63488,)\n",
            "Element 424 shape: (63488,)\n",
            "Element 425 shape: (63488,)\n",
            "Element 426 shape: (63488,)\n",
            "Element 427 shape: (63488,)\n",
            "Element 428 shape: (64512,)\n",
            "Element 429 shape: (64512,)\n",
            "Element 430 shape: (63488,)\n",
            "Element 431 shape: (63488,)\n",
            "Element 432 shape: (63488,)\n",
            "Element 433 shape: (64512,)\n",
            "Element 434 shape: (63488,)\n",
            "Element 435 shape: (63488,)\n",
            "Element 436 shape: (63488,)\n",
            "Element 437 shape: (63488,)\n",
            "Element 438 shape: (63488,)\n",
            "Element 439 shape: (63488,)\n",
            "Element 440 shape: (63488,)\n",
            "Element 441 shape: (63488,)\n",
            "Element 442 shape: (63488,)\n",
            "Element 443 shape: (63488,)\n",
            "Element 444 shape: (63488,)\n",
            "Element 445 shape: (63488,)\n",
            "Element 446 shape: (63488,)\n",
            "Element 447 shape: (63488,)\n",
            "Element 448 shape: (64512,)\n",
            "Element 449 shape: (63488,)\n",
            "Element 450 shape: (63488,)\n",
            "Element 451 shape: (64512,)\n",
            "Element 452 shape: (63488,)\n",
            "Element 453 shape: (63488,)\n",
            "Element 454 shape: (63488,)\n",
            "Element 455 shape: (64512,)\n",
            "Element 456 shape: (63488,)\n",
            "Element 457 shape: (63488,)\n",
            "Element 458 shape: (63488,)\n",
            "Element 459 shape: (63488,)\n",
            "Element 460 shape: (63488,)\n",
            "Element 461 shape: (63488,)\n",
            "Element 462 shape: (63488,)\n",
            "Element 463 shape: (63488,)\n",
            "Element 464 shape: (63488,)\n",
            "Element 465 shape: (63488,)\n",
            "Element 466 shape: (63488,)\n",
            "Element 467 shape: (63488,)\n",
            "Element 468 shape: (63488,)\n",
            "Element 469 shape: (63488,)\n",
            "Element 470 shape: (63488,)\n",
            "Element 471 shape: (63488,)\n",
            "Element 472 shape: (63488,)\n",
            "Element 473 shape: (63488,)\n",
            "Element 474 shape: (63488,)\n",
            "Element 475 shape: (63488,)\n",
            "Element 476 shape: (63488,)\n",
            "Element 477 shape: (63488,)\n",
            "Element 478 shape: (64512,)\n",
            "Element 479 shape: (64512,)\n",
            "Element 480 shape: (63488,)\n",
            "Element 481 shape: (63488,)\n",
            "Element 482 shape: (63488,)\n",
            "Element 483 shape: (63488,)\n",
            "Element 484 shape: (63488,)\n",
            "Element 485 shape: (63488,)\n",
            "Element 486 shape: (63488,)\n",
            "Element 487 shape: (63488,)\n",
            "Element 488 shape: (63488,)\n",
            "Element 489 shape: (63488,)\n",
            "Element 490 shape: (63488,)\n",
            "Element 491 shape: (63488,)\n",
            "Element 492 shape: (64512,)\n",
            "Element 493 shape: (63488,)\n",
            "Element 494 shape: (63488,)\n",
            "Element 495 shape: (63488,)\n",
            "Element 496 shape: (63488,)\n",
            "Element 497 shape: (63488,)\n",
            "Element 498 shape: (63488,)\n",
            "Element 499 shape: (63488,)\n",
            "Element 500 shape: (63488,)\n",
            "Element 501 shape: (63488,)\n",
            "Element 502 shape: (63488,)\n",
            "Element 503 shape: (63488,)\n",
            "Element 504 shape: (63488,)\n",
            "Element 505 shape: (63488,)\n",
            "Element 506 shape: (63488,)\n",
            "Element 507 shape: (63488,)\n",
            "Element 508 shape: (63488,)\n",
            "Element 509 shape: (63488,)\n",
            "Element 510 shape: (63488,)\n",
            "Element 511 shape: (63488,)\n",
            "Element 512 shape: (63488,)\n",
            "Element 513 shape: (63488,)\n",
            "Element 514 shape: (63488,)\n",
            "Element 515 shape: (63488,)\n",
            "Element 516 shape: (63488,)\n",
            "Element 517 shape: (63488,)\n",
            "Element 518 shape: (63488,)\n",
            "Element 519 shape: (63488,)\n",
            "Element 520 shape: (63488,)\n",
            "Element 521 shape: (63488,)\n",
            "Element 522 shape: (63488,)\n",
            "Element 523 shape: (63488,)\n",
            "Element 524 shape: (63488,)\n",
            "Element 525 shape: (63488,)\n",
            "Element 526 shape: (63488,)\n",
            "Element 527 shape: (63488,)\n",
            "Element 528 shape: (63488,)\n",
            "Element 529 shape: (63488,)\n",
            "Element 530 shape: (63488,)\n",
            "Element 531 shape: (63488,)\n",
            "Element 532 shape: (63488,)\n",
            "Element 533 shape: (63488,)\n",
            "Element 534 shape: (63488,)\n",
            "Element 535 shape: (63488,)\n",
            "Element 536 shape: (63488,)\n",
            "Element 537 shape: (63488,)\n",
            "Element 538 shape: (64512,)\n",
            "Element 539 shape: (63488,)\n",
            "Element 540 shape: (63488,)\n",
            "Element 541 shape: (63488,)\n",
            "Element 542 shape: (63488,)\n",
            "Element 543 shape: (63488,)\n",
            "Element 544 shape: (63488,)\n",
            "Element 545 shape: (63488,)\n",
            "Element 546 shape: (63488,)\n",
            "Element 547 shape: (63488,)\n",
            "Element 548 shape: (63488,)\n",
            "Element 549 shape: (63488,)\n",
            "Element 550 shape: (63488,)\n",
            "Element 551 shape: (63488,)\n",
            "Element 552 shape: (63488,)\n",
            "Element 553 shape: (63488,)\n",
            "Element 554 shape: (63488,)\n",
            "Element 555 shape: (63488,)\n",
            "Element 556 shape: (63488,)\n",
            "Element 557 shape: (63488,)\n",
            "Element 558 shape: (63488,)\n",
            "Element 559 shape: (63488,)\n",
            "Element 560 shape: (63488,)\n",
            "Element 561 shape: (63488,)\n",
            "Element 562 shape: (63488,)\n",
            "Element 563 shape: (63488,)\n",
            "Element 564 shape: (63488,)\n",
            "Element 565 shape: (63488,)\n",
            "Element 566 shape: (63488,)\n",
            "Element 567 shape: (63488,)\n",
            "Element 568 shape: (63488,)\n",
            "Element 569 shape: (63488,)\n",
            "Element 570 shape: (63488,)\n",
            "Element 571 shape: (63488,)\n",
            "Element 572 shape: (63488,)\n",
            "Element 573 shape: (63488,)\n",
            "Element 574 shape: (63488,)\n",
            "Element 575 shape: (63488,)\n",
            "Element 576 shape: (63488,)\n",
            "Element 577 shape: (63488,)\n",
            "Element 578 shape: (63488,)\n",
            "Element 579 shape: (63488,)\n",
            "Element 580 shape: (63488,)\n",
            "Element 581 shape: (63488,)\n",
            "Element 582 shape: (63488,)\n",
            "Element 583 shape: (64512,)\n",
            "Element 584 shape: (63488,)\n",
            "Element 585 shape: (63488,)\n",
            "Element 586 shape: (63488,)\n",
            "Element 587 shape: (63488,)\n",
            "Element 588 shape: (63488,)\n",
            "Element 589 shape: (63488,)\n",
            "Element 590 shape: (64512,)\n",
            "Element 591 shape: (63488,)\n",
            "Element 592 shape: (63488,)\n",
            "Element 593 shape: (63488,)\n",
            "Element 594 shape: (63488,)\n",
            "Element 595 shape: (63488,)\n",
            "Element 596 shape: (63488,)\n",
            "Element 597 shape: (64512,)\n",
            "Element 598 shape: (63488,)\n",
            "Element 599 shape: (63488,)\n",
            "Element 600 shape: (63488,)\n",
            "Element 601 shape: (63488,)\n",
            "Element 602 shape: (63488,)\n",
            "Element 603 shape: (63488,)\n",
            "Element 604 shape: (63488,)\n",
            "Element 605 shape: (63488,)\n",
            "Element 606 shape: (63488,)\n",
            "Element 607 shape: (63488,)\n",
            "Element 608 shape: (63488,)\n",
            "Element 609 shape: (63488,)\n",
            "Element 610 shape: (63488,)\n",
            "Element 611 shape: (63488,)\n",
            "Element 612 shape: (63488,)\n",
            "Element 613 shape: (63488,)\n",
            "Element 614 shape: (63488,)\n",
            "Element 615 shape: (63488,)\n",
            "Element 616 shape: (63488,)\n",
            "Element 617 shape: (63488,)\n",
            "Element 618 shape: (63488,)\n",
            "Element 619 shape: (63488,)\n",
            "Element 620 shape: (63488,)\n",
            "Element 621 shape: (63488,)\n",
            "Element 622 shape: (63488,)\n",
            "Element 623 shape: (63488,)\n",
            "Element 624 shape: (63488,)\n",
            "Element 625 shape: (63488,)\n",
            "Element 626 shape: (63488,)\n",
            "Element 627 shape: (63488,)\n",
            "Element 628 shape: (63488,)\n",
            "Element 629 shape: (63488,)\n",
            "Element 630 shape: (63488,)\n",
            "Element 631 shape: (63488,)\n",
            "Element 632 shape: (63488,)\n",
            "Element 633 shape: (63488,)\n",
            "Element 634 shape: (63488,)\n",
            "Element 635 shape: (63488,)\n",
            "Element 636 shape: (63488,)\n",
            "Element 637 shape: (63488,)\n",
            "Element 638 shape: (63488,)\n",
            "Element 639 shape: (63488,)\n",
            "Element 640 shape: (63488,)\n",
            "Element 641 shape: (63488,)\n",
            "Element 642 shape: (63488,)\n",
            "Element 643 shape: (63488,)\n",
            "Element 644 shape: (63488,)\n",
            "Element 645 shape: (63488,)\n",
            "Element 646 shape: (63488,)\n",
            "Element 647 shape: (63488,)\n",
            "Element 648 shape: (63488,)\n",
            "Element 649 shape: (63488,)\n",
            "Element 650 shape: (63488,)\n",
            "Element 651 shape: (63488,)\n",
            "Element 652 shape: (63488,)\n",
            "Element 653 shape: (63488,)\n",
            "Element 654 shape: (63488,)\n",
            "Element 655 shape: (63488,)\n",
            "Element 656 shape: (63488,)\n",
            "Element 657 shape: (63488,)\n",
            "Element 658 shape: (63488,)\n",
            "Element 659 shape: (63488,)\n",
            "Element 660 shape: (63488,)\n",
            "Element 661 shape: (63488,)\n",
            "Element 662 shape: (63488,)\n",
            "Element 663 shape: (63488,)\n",
            "Element 664 shape: (63488,)\n",
            "Element 665 shape: (63488,)\n",
            "Element 666 shape: (63488,)\n",
            "Element 667 shape: (63488,)\n",
            "Element 668 shape: (63488,)\n",
            "Element 669 shape: (63488,)\n",
            "Element 670 shape: (63488,)\n",
            "Element 671 shape: (63488,)\n",
            "Element 672 shape: (63488,)\n",
            "Element 673 shape: (63488,)\n",
            "Element 674 shape: (63488,)\n",
            "Element 675 shape: (63488,)\n",
            "Element 676 shape: (63488,)\n",
            "Element 677 shape: (63488,)\n",
            "Element 678 shape: (63488,)\n",
            "Element 679 shape: (63488,)\n",
            "Element 680 shape: (63488,)\n",
            "Element 681 shape: (63488,)\n",
            "Element 682 shape: (63488,)\n",
            "Element 683 shape: (63488,)\n",
            "Element 684 shape: (63488,)\n",
            "Element 685 shape: (63488,)\n",
            "Element 686 shape: (63488,)\n",
            "Element 687 shape: (63488,)\n",
            "Element 688 shape: (63488,)\n",
            "Element 689 shape: (63488,)\n",
            "Element 690 shape: (63488,)\n",
            "Element 691 shape: (63488,)\n",
            "Element 692 shape: (63488,)\n",
            "Element 693 shape: (63488,)\n",
            "Element 694 shape: (63488,)\n",
            "Element 695 shape: (63488,)\n",
            "Element 696 shape: (63488,)\n",
            "Element 697 shape: (63488,)\n",
            "Element 698 shape: (63488,)\n",
            "Element 699 shape: (63488,)\n",
            "Element 700 shape: (63488,)\n",
            "Element 701 shape: (63488,)\n",
            "Element 702 shape: (63488,)\n",
            "Element 703 shape: (63488,)\n",
            "Element 704 shape: (63488,)\n",
            "Element 705 shape: (63488,)\n",
            "Element 706 shape: (63488,)\n",
            "Element 707 shape: (63488,)\n",
            "Element 708 shape: (63488,)\n",
            "Element 709 shape: (63488,)\n",
            "Element 710 shape: (63488,)\n",
            "Element 711 shape: (63488,)\n",
            "Element 712 shape: (63488,)\n",
            "Element 713 shape: (63488,)\n",
            "Element 714 shape: (63488,)\n",
            "Element 715 shape: (63488,)\n",
            "Element 716 shape: (63488,)\n",
            "Element 717 shape: (63488,)\n",
            "Element 718 shape: (63488,)\n",
            "Element 719 shape: (63488,)\n",
            "Element 720 shape: (63488,)\n",
            "Element 721 shape: (63488,)\n",
            "Element 722 shape: (63488,)\n",
            "Element 723 shape: (63488,)\n",
            "Element 724 shape: (63488,)\n",
            "Element 725 shape: (63488,)\n",
            "Element 726 shape: (63488,)\n",
            "Element 727 shape: (63488,)\n",
            "Element 728 shape: (63488,)\n",
            "Element 729 shape: (63488,)\n",
            "Element 730 shape: (63488,)\n",
            "Element 731 shape: (63488,)\n",
            "Element 732 shape: (63488,)\n",
            "Element 733 shape: (63488,)\n",
            "Element 734 shape: (63488,)\n",
            "Element 735 shape: (63488,)\n",
            "Element 736 shape: (63488,)\n",
            "Element 737 shape: (63488,)\n",
            "Element 738 shape: (63488,)\n",
            "Element 739 shape: (63488,)\n",
            "Element 740 shape: (63488,)\n",
            "Element 741 shape: (63488,)\n",
            "Element 742 shape: (63488,)\n",
            "Element 743 shape: (63488,)\n",
            "Element 744 shape: (63488,)\n",
            "Element 745 shape: (63488,)\n",
            "Element 746 shape: (63488,)\n",
            "Element 747 shape: (63488,)\n",
            "Element 748 shape: (63488,)\n",
            "Element 749 shape: (63488,)\n",
            "Element 750 shape: (63488,)\n",
            "Element 751 shape: (63488,)\n",
            "Element 752 shape: (63488,)\n",
            "Element 753 shape: (63488,)\n",
            "Element 754 shape: (63488,)\n",
            "Element 755 shape: (63488,)\n",
            "Element 756 shape: (63488,)\n",
            "Element 757 shape: (63488,)\n",
            "Element 758 shape: (63488,)\n",
            "Element 759 shape: (63488,)\n",
            "Element 760 shape: (63488,)\n",
            "Element 761 shape: (63488,)\n",
            "Element 762 shape: (63488,)\n",
            "Element 763 shape: (63488,)\n",
            "Element 764 shape: (63488,)\n",
            "Element 765 shape: (63488,)\n",
            "Element 766 shape: (63488,)\n",
            "Element 767 shape: (63488,)\n",
            "Element 768 shape: (63488,)\n",
            "Element 769 shape: (63488,)\n",
            "Element 770 shape: (63488,)\n",
            "Element 771 shape: (63488,)\n",
            "Element 772 shape: (63488,)\n",
            "Element 773 shape: (63488,)\n",
            "Element 774 shape: (63488,)\n",
            "Element 775 shape: (63488,)\n",
            "Element 776 shape: (63488,)\n",
            "Element 777 shape: (63488,)\n",
            "Element 778 shape: (63488,)\n",
            "Element 779 shape: (63488,)\n",
            "Element 780 shape: (63488,)\n",
            "Element 781 shape: (63488,)\n",
            "Element 782 shape: (63488,)\n",
            "Element 783 shape: (63488,)\n",
            "Element 784 shape: (63488,)\n",
            "Element 785 shape: (63488,)\n",
            "Element 786 shape: (63488,)\n",
            "Element 787 shape: (63488,)\n",
            "Element 788 shape: (63488,)\n",
            "Element 789 shape: (63488,)\n",
            "Element 790 shape: (63488,)\n",
            "Element 791 shape: (63488,)\n",
            "Element 792 shape: (63488,)\n",
            "Element 793 shape: (63488,)\n",
            "Element 794 shape: (63488,)\n",
            "Element 795 shape: (63488,)\n",
            "Element 796 shape: (63488,)\n",
            "Element 797 shape: (63488,)\n",
            "Element 798 shape: (63488,)\n",
            "Element 799 shape: (63488,)\n",
            "Element 800 shape: (63488,)\n",
            "Element 801 shape: (63488,)\n",
            "Element 802 shape: (63488,)\n",
            "Element 803 shape: (63488,)\n",
            "Element 804 shape: (63488,)\n",
            "Element 805 shape: (63488,)\n",
            "Element 806 shape: (63488,)\n",
            "Element 807 shape: (63488,)\n",
            "Element 808 shape: (63488,)\n",
            "Element 809 shape: (63488,)\n",
            "Element 810 shape: (63488,)\n",
            "Element 811 shape: (63488,)\n",
            "Element 812 shape: (63488,)\n",
            "Element 813 shape: (63488,)\n",
            "Element 814 shape: (63488,)\n",
            "Element 815 shape: (63488,)\n",
            "Element 816 shape: (63488,)\n",
            "Element 817 shape: (63488,)\n",
            "Element 818 shape: (63488,)\n",
            "Element 819 shape: (63488,)\n",
            "Element 820 shape: (63488,)\n",
            "Element 821 shape: (63488,)\n",
            "Element 822 shape: (63488,)\n",
            "Element 823 shape: (63488,)\n",
            "Element 824 shape: (63488,)\n",
            "Element 825 shape: (63488,)\n",
            "Element 826 shape: (63488,)\n",
            "Element 827 shape: (63488,)\n",
            "Element 828 shape: (63488,)\n",
            "Element 829 shape: (63488,)\n",
            "Element 830 shape: (63488,)\n",
            "Element 831 shape: (63488,)\n",
            "Element 832 shape: (63488,)\n",
            "Element 833 shape: (63488,)\n",
            "Element 834 shape: (63488,)\n",
            "Element 835 shape: (63488,)\n",
            "Element 836 shape: (63488,)\n",
            "Element 837 shape: (63488,)\n",
            "Element 838 shape: (63488,)\n",
            "Element 839 shape: (63488,)\n",
            "Element 840 shape: (63488,)\n",
            "Element 841 shape: (63488,)\n",
            "Element 842 shape: (63488,)\n",
            "Element 843 shape: (63488,)\n",
            "Element 844 shape: (63488,)\n",
            "Element 845 shape: (63488,)\n",
            "Element 846 shape: (63488,)\n",
            "Element 847 shape: (63488,)\n",
            "Element 848 shape: (63488,)\n",
            "Element 849 shape: (63488,)\n",
            "Element 850 shape: (63488,)\n",
            "Element 851 shape: (63488,)\n",
            "Element 852 shape: (63488,)\n",
            "Element 853 shape: (63488,)\n",
            "Element 854 shape: (63488,)\n",
            "Element 855 shape: (63488,)\n",
            "Element 856 shape: (63488,)\n",
            "Element 857 shape: (63488,)\n",
            "Element 858 shape: (63488,)\n",
            "Element 859 shape: (63488,)\n",
            "Element 860 shape: (63488,)\n",
            "Element 861 shape: (63488,)\n",
            "Element 862 shape: (63488,)\n",
            "Element 863 shape: (63488,)\n",
            "Element 864 shape: (63488,)\n",
            "Element 865 shape: (63488,)\n",
            "Element 866 shape: (63488,)\n",
            "Element 867 shape: (63488,)\n",
            "Element 868 shape: (63488,)\n",
            "Element 869 shape: (63488,)\n",
            "Element 870 shape: (63488,)\n",
            "Element 871 shape: (63488,)\n",
            "Element 872 shape: (63488,)\n",
            "Element 873 shape: (63488,)\n",
            "Element 874 shape: (63488,)\n",
            "Element 875 shape: (63488,)\n",
            "Element 876 shape: (63488,)\n",
            "Element 877 shape: (63488,)\n",
            "Element 878 shape: (63488,)\n",
            "Element 879 shape: (63488,)\n",
            "Element 880 shape: (63488,)\n",
            "Element 881 shape: (63488,)\n",
            "Element 882 shape: (63488,)\n",
            "Element 883 shape: (63488,)\n",
            "Element 884 shape: (63488,)\n",
            "Element 885 shape: (63488,)\n",
            "Element 886 shape: (63488,)\n",
            "Element 887 shape: (63488,)\n",
            "Element 888 shape: (63488,)\n",
            "Element 889 shape: (63488,)\n",
            "Element 890 shape: (63488,)\n",
            "Element 891 shape: (63488,)\n",
            "Element 892 shape: (63488,)\n",
            "Element 893 shape: (63488,)\n",
            "Element 894 shape: (63488,)\n",
            "Element 895 shape: (63488,)\n",
            "Element 896 shape: (63488,)\n",
            "Element 897 shape: (63488,)\n",
            "Element 898 shape: (63488,)\n",
            "Element 899 shape: (63488,)\n",
            "Element 900 shape: (63488,)\n",
            "Element 901 shape: (63488,)\n",
            "Element 902 shape: (63488,)\n",
            "Element 903 shape: (63488,)\n",
            "Element 904 shape: (63488,)\n",
            "Element 905 shape: (63488,)\n",
            "Element 906 shape: (63488,)\n",
            "Element 907 shape: (63488,)\n",
            "Element 908 shape: (63488,)\n",
            "Element 909 shape: (63488,)\n",
            "Element 910 shape: (63488,)\n",
            "Element 911 shape: (63488,)\n",
            "Element 912 shape: (63488,)\n",
            "Element 913 shape: (63488,)\n",
            "Element 914 shape: (63488,)\n",
            "Element 915 shape: (63488,)\n",
            "Element 916 shape: (63488,)\n",
            "Element 917 shape: (63488,)\n",
            "Element 918 shape: (63488,)\n",
            "Element 919 shape: (63488,)\n",
            "Element 920 shape: (64512,)\n",
            "Element 921 shape: (63488,)\n",
            "Element 922 shape: (63488,)\n",
            "Element 923 shape: (63488,)\n",
            "Element 924 shape: (63488,)\n",
            "Element 925 shape: (63488,)\n",
            "Element 926 shape: (63488,)\n",
            "Element 927 shape: (63488,)\n",
            "Element 928 shape: (63488,)\n",
            "Element 929 shape: (63488,)\n",
            "Element 930 shape: (63488,)\n",
            "Element 931 shape: (63488,)\n",
            "Element 932 shape: (63488,)\n",
            "Element 933 shape: (64512,)\n",
            "Element 934 shape: (63488,)\n",
            "Element 935 shape: (63488,)\n",
            "Element 936 shape: (63488,)\n",
            "Element 937 shape: (63488,)\n",
            "Element 938 shape: (63488,)\n",
            "Element 939 shape: (63488,)\n",
            "Element 940 shape: (63488,)\n",
            "Element 941 shape: (63488,)\n",
            "Element 942 shape: (63488,)\n",
            "Element 943 shape: (63488,)\n",
            "Element 944 shape: (63488,)\n",
            "Element 945 shape: (63488,)\n",
            "Element 946 shape: (63488,)\n",
            "Element 947 shape: (63488,)\n",
            "Element 948 shape: (63488,)\n",
            "Element 949 shape: (63488,)\n",
            "Element 950 shape: (63488,)\n",
            "Element 951 shape: (63488,)\n",
            "Element 952 shape: (63488,)\n",
            "Element 953 shape: (63488,)\n",
            "Element 954 shape: (63488,)\n",
            "Element 955 shape: (63488,)\n",
            "Element 956 shape: (63488,)\n",
            "Element 957 shape: (63488,)\n",
            "Element 958 shape: (63488,)\n",
            "Element 959 shape: (63488,)\n",
            "Element 960 shape: (63488,)\n",
            "Element 961 shape: (64512,)\n",
            "Element 962 shape: (63488,)\n",
            "Element 963 shape: (63488,)\n",
            "Element 964 shape: (63488,)\n",
            "Element 965 shape: (63488,)\n",
            "Element 966 shape: (63488,)\n",
            "Element 967 shape: (63488,)\n",
            "Element 968 shape: (63488,)\n",
            "Element 969 shape: (63488,)\n",
            "Element 970 shape: (63488,)\n",
            "Element 971 shape: (63488,)\n",
            "Element 972 shape: (63488,)\n",
            "Element 973 shape: (63488,)\n",
            "Element 974 shape: (63488,)\n",
            "Element 975 shape: (63488,)\n",
            "Element 976 shape: (63488,)\n",
            "Element 977 shape: (63488,)\n",
            "Element 978 shape: (63488,)\n",
            "Element 979 shape: (63488,)\n",
            "Element 980 shape: (63488,)\n",
            "Element 981 shape: (63488,)\n",
            "Element 982 shape: (63488,)\n",
            "Element 983 shape: (63488,)\n",
            "Element 984 shape: (63488,)\n",
            "Element 985 shape: (63488,)\n",
            "Element 986 shape: (63488,)\n",
            "Element 987 shape: (63488,)\n",
            "Element 988 shape: (63488,)\n",
            "Element 989 shape: (63488,)\n",
            "Element 990 shape: (63488,)\n",
            "Element 991 shape: (63488,)\n",
            "Element 992 shape: (63488,)\n",
            "Element 993 shape: (63488,)\n",
            "Element 994 shape: (63488,)\n",
            "Element 995 shape: (63488,)\n",
            "Element 996 shape: (63488,)\n",
            "Element 997 shape: (63488,)\n",
            "Element 998 shape: (63488,)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import numpy as np\n",
        "\n",
        "def pad_sequences(sequences, maxlen=None, dtype='int32', padding='post', truncating='post', value=0.0):\n",
        "    \"\"\"Pads sequences to the same length.\n",
        "\n",
        "    Args:\n",
        "        sequences: List of sequences (NumPy arrays).\n",
        "        maxlen: Maximum length of all sequences. If None, set to the length of the longest sequence.\n",
        "        dtype: Data type of the padded sequences.\n",
        "        padding: 'pre' or 'post', pad either before or after each sequence.\n",
        "        truncating: 'pre' or 'post', remove values from sequences larger than `maxlen` either\n",
        "            at the beginning or the end of the sequences.\n",
        "        value: Value to pad the sequences with.\n",
        "\n",
        "    Returns:\n",
        "        NumPy array with the padded sequences.\n",
        "    \"\"\"\n",
        "    lengths = [len(s) for s in sequences]\n",
        "    if maxlen is None:\n",
        "        maxlen = np.max(lengths)\n",
        "\n",
        "    num_samples = len(sequences)\n",
        "    padded_sequences = np.full((num_samples, maxlen), value, dtype=dtype)\n",
        "    for i, s in enumerate(sequences):\n",
        "        if truncating == 'pre':\n",
        "            trunc = s[-maxlen:]\n",
        "        elif truncating == 'post':\n",
        "            trunc = s[:maxlen]\n",
        "        else:\n",
        "            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n",
        "\n",
        "        if padding == 'post':\n",
        "            padded_sequences[i, :len(trunc)] = trunc\n",
        "        elif padding == 'pre':\n",
        "            padded_sequences[i, -len(trunc):] = trunc\n",
        "        else:\n",
        "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
        "\n",
        "    return padded_sequences\n",
        "\n",
        "# ... (rest of your code)\n",
        "\n",
        "# After extracting features:\n",
        "nd_padded = pad_sequences(nd, dtype='float32')\n",
        "\n",
        "# Now you can try creating the NumPy array:\n",
        "nd_array = np.array(nd_padded)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "bgJxYYSlSzoY"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nd , ns = [] , []"
      ],
      "metadata": {
        "id": "PAMTR7aSJPtl"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for genre_dir in Dict:\n",
        "  genre_label = genre_dir.split('/')[-1]\n",
        "  if genre_label not in Dictionary:\n",
        "    continue\n",
        "  label = Dictionary[genre_label]\n",
        "  for file_name in os.listdir (genre_dir):\n",
        "    if file_name.endswith('.wav'):\n",
        "      file_path = os.path.join(genre_dir, file_name)\n",
        "      wav_data = load_wav(file_path)\n",
        "      if wav_data is not None:\n",
        "        features = extract_features3(wav_data)\n",
        "        if features is not None:\n",
        "          nd.append(features)\n",
        "          ns.append(label)\n"
      ],
      "metadata": {
        "id": "-XVenRM6JUcd"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ns = np.array(ns)"
      ],
      "metadata": {
        "id": "8Lm6_u0dJW-J"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nd_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnWgWfYGTSw0",
        "outputId": "74acfef8-c346-4da1-82a2-cf01c63bccbd"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(999, 64512)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nd_array = nd_array.reshape(nd_array.shape[0] , -1)"
      ],
      "metadata": {
        "id": "O_Fa9_YrPe2t"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM , Reshape , Bidirectional"
      ],
      "metadata": {
        "id": "VpvLJ4ZwWxTw"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dif_shpe = (nd_array.shape[1] ,)\n",
        "new_model = Sequential()\n",
        "new_model.add(InputLayer(input_shape=dif_shpe))\n",
        "new_model.add(Dense(256 , activation = 'relu'))\n",
        "new_model.add(Dropout(0.5))\n",
        "new_model.add(Dense(128 , activation = 'relu'))\n",
        "new_model.add(Dropout(0.5))\n",
        "new_model.add(Dense(64 , activation = 'relu'))\n",
        "new_model.add(Dense(10 , activation = 'softmax'))\n",
        "new_model.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "CSfA9sldSAxG"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saJBW7cGSWat",
        "outputId": "2ecce756-c1d3-4d58-a367-aa511fefcf39"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_27 (Dense)            (None, 256)               16515328  \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16557130 (63.16 MB)\n",
            "Trainable params: 16557130 (63.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.fit(nd_array , ns , epochs = 50 , batch_size = 32 , validation_split = 0.2 ,\n",
        "              callbacks = [\n",
        "                  tf.keras.callbacks.EarlyStopping(\n",
        "                      monitor='val_loss',\n",
        "                      patience=3,\n",
        "                      restore_best_weights=True) ,\n",
        "                    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                      monitor='val_loss',\n",
        "                      factor=0.2,\n",
        "                      patience=2,\n",
        "                      min_lr=0.001)\n",
        "\n",
        "          ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWRPNGo7TZvf",
        "outputId": "26bed903-c1b6-43f7-bc39-5505c8b2e4a5"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 12s 451ms/step - loss: 2.1774 - accuracy: 0.3855 - val_loss: 4.0587 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 10s 388ms/step - loss: 1.0713 - accuracy: 0.6483 - val_loss: 5.8449 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 10s 401ms/step - loss: 0.7678 - accuracy: 0.7422 - val_loss: 5.0721 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 9s 375ms/step - loss: 0.7232 - accuracy: 0.7885 - val_loss: 5.6295 - val_accuracy: 0.0000e+00 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d8736fbdb10>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: check the accuracy\n",
        "\n",
        "# ... (your existing code) ...\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = new_model.evaluate(nd_array, ns, verbose=0)\n",
        "print('Accuracy: %.2f%%' % (accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rT6rZD5U3Fx",
        "outputId": "28848fa0-a758-42bb-c8f0-15beb3cc4270"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 60.66%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CKMHxROOVsr4"
      },
      "execution_count": 108,
      "outputs": []
    }
  ]
}